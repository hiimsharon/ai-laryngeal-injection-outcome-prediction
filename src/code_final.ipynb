{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc6487-d8db-44b5-9d43-2466b842fdf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 把語音 wav 檔整理成可訓練的資料流程：\n",
    "# 1) 讀取 CSV（包含 wav 檔名與 outcome 標籤）\n",
    "# 2) 只保留術前資料（status = S）\n",
    "# 3) 每個 wav 轉成兩種影像：Mel 與 STFT（PNG）\n",
    "# 4) 用分層方式做 5-fold 切分，讓每折正負比例接近\n",
    "#\n",
    "# 輸入\n",
    "# - /home/jovyan/114-1_HA/data/0604_final_REFCV.csv\n",
    "#   欄位必須有 sound.files（wav 檔名）、outcome（0/1）\n",
    "# - /home/jovyan/114-1_HA/data/a_slide/（wav 檔案資料夾）\n",
    "#\n",
    "# 輸出\n",
    "# - Step1：manifest_S_only.csv（術前 S 的有效清單）\n",
    "# - Step2：Mel / STFT PNG（存到 data/pic_v4/mel 與 data/pic_v4/stft）\n",
    "# - Step3：splits（五折的 train/val index；分布會寫進 log）\n",
    "# - Log：/home/jovyan/114-1_HA/log_v4/run_YYYYMMDD_HHMMSS.log\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Step0：全域設定 + 路徑 + logger + 小工具\n",
    "# -----------------------------------------------------------------------------\n",
    "# 在這一段把常用設定集中起來，把資料夾與輸出位置先準備好，\n",
    "# 這樣後面每一步都能用同一套路徑與紀錄方式跑完。\n",
    "# =============================================================================\n",
    "import os, re, time, json, math\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 專案根目錄放在這裡，後面所有路徑都從這裡往下接\n",
    "# -------------------------\n",
    "BASE_DIR = Path(\"/home/jovyan/114-1_HA\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 輸入與輸出路徑集中管理\n",
    "# -------------------------\n",
    "DATA_DIR      = BASE_DIR / \"data\"\n",
    "CSV_PATH      = DATA_DIR / \"0604_final_REFCV.csv\"\n",
    "AUDIO_DIR     = DATA_DIR / \"a_slide\"\n",
    "\n",
    "PIC_DIR       = DATA_DIR / \"pic_v4\"\n",
    "MEL_PIC_DIR   = PIC_DIR / \"mel\"\n",
    "STFT_PIC_DIR  = PIC_DIR / \"stft\"\n",
    "\n",
    "OUT_DIR       = DATA_DIR / \"out\"\n",
    "CM_DIR        = OUT_DIR / \"cm\"\n",
    "ROC_DIR       = OUT_DIR / \"roc\"\n",
    "GRADCAM_DIR   = OUT_DIR / \"gradcam\"\n",
    "GRADCAM_MEL_DIR   = GRADCAM_DIR / \"mel\"\n",
    "GRADCAM_STFT_DIR  = GRADCAM_DIR / \"stft\"\n",
    "GRADCAM_DUAL_DIR  = GRADCAM_DIR / \"dual\"\n",
    "PROB_DIR      = OUT_DIR / \"prob_margin\"\n",
    "CSV_OUT_DIR   = OUT_DIR / \"csv\"\n",
    "\n",
    "LOG_DIR       = BASE_DIR / \"log_v4\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 先把會用到的資料夾都建好\n",
    "# -------------------------\n",
    "for d in [\n",
    "    MEL_PIC_DIR, STFT_PIC_DIR,\n",
    "    CM_DIR, ROC_DIR,\n",
    "    GRADCAM_MEL_DIR, GRADCAM_STFT_DIR, GRADCAM_DUAL_DIR,\n",
    "    PROB_DIR, CSV_OUT_DIR,\n",
    "    LOG_DIR\n",
    "]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 把 Step1 產出的清單固定成一個檔案，後面都直接讀它\n",
    "# -------------------------\n",
    "MANIFEST_PATH = DATA_DIR / \"manifest_S_only.csv\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 常調的參數，之後要調整不會漏\n",
    "# -------------------------\n",
    "# 音訊讀取設定\n",
    "SR = 16000\n",
    "DURATION_SEC = 10.0\n",
    "N_SAMPLES = int(SR * DURATION_SEC)\n",
    "\n",
    "# 圖像輸入大小（後面 CNN\n",
    "IMG_H, IMG_W = 224, 224\n",
    "\n",
    "# 交叉驗證設定\n",
    "N_FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# 影像 CNN 的訓練參數（如果 Step4 另外有一套，這裡就當預設）\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "\n",
    "# 只取術前資料\n",
    "USE_STATUS = \"S\"\n",
    "\n",
    "# 在每一折做 Grad-CAM 會取多少張\n",
    "GRADCAM_N_SAMPLES_PER_FOLD = 4\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 把 logger 做成同時輸出到螢幕與檔案\n",
    "# -------------------------\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_PATH = LOG_DIR / f\"run_{RUN_TAG}.log\"\n",
    "\n",
    "def build_logger(log_path: Path) -> logging.Logger:\n",
    "    logger = logging.getLogger(f\"voice_proj_{log_path.stem}\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = False\n",
    "    while logger.handlers:\n",
    "        logger.handlers.pop()\n",
    "\n",
    "    fmt = logging.Formatter(\n",
    "        fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "    fh = logging.FileHandler(log_path, mode=\"w\", encoding=\"utf-8\")\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(fmt)\n",
    "    logger.addHandler(sh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = build_logger(LOG_PATH)\n",
    "\n",
    "logger.info(\"==== Start run ====\")\n",
    "logger.info(f\"BASE_DIR={BASE_DIR}\")\n",
    "logger.info(f\"CSV_PATH={CSV_PATH}\")\n",
    "logger.info(f\"AUDIO_DIR={AUDIO_DIR}\")\n",
    "logger.info(f\"MEL_PIC_DIR={MEL_PIC_DIR}\")\n",
    "logger.info(f\"STFT_PIC_DIR={STFT_PIC_DIR}\")\n",
    "logger.info(f\"OUT_DIR={OUT_DIR}\")\n",
    "logger.info(f\"LOG_PATH={LOG_PATH}\")\n",
    "logger.info(f\"HP: SR={SR}, DURATION_SEC={DURATION_SEC}, IMG={IMG_H}x{IMG_W}, folds={N_FOLDS}\")\n",
    "logger.info(f\"Use only status={USE_STATUS}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 用檔名規則解析 wav 的資訊，例如 5_S1_3.wav\n",
    "# 格式是 pid_statusvowel_clip.wav\n",
    "# -------------------------\n",
    "FNAME_RE = re.compile(\n",
    "    r\"^(?P<pid>\\d+)_(?P<status>[SA])(?P<vowel>\\d+)_(?P<clip>\\d+)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_wav_name(fname: str):\n",
    "    m = FNAME_RE.match(fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    return {\n",
    "        \"patient_id\": int(m.group(\"pid\")),\n",
    "        \"status\": m.group(\"status\").upper(),\n",
    "        \"vowel_id\": int(m.group(\"vowel\")),\n",
    "        \"clip_id\": int(m.group(\"clip\")),\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "#兩個小工具，後面做統計與 log 會一直用到\n",
    "# -------------------------\n",
    "def count_pos_neg(y_arr):\n",
    "    y_arr = np.asarray(y_arr).astype(int)\n",
    "    n_pos = int((y_arr == 1).sum())\n",
    "    n_neg = int((y_arr == 0).sum())\n",
    "    return n_pos, n_neg\n",
    "\n",
    "def pos_rate(n_pos, n_neg):\n",
    "    total = n_pos + n_neg\n",
    "    return float(n_pos / total) if total > 0 else float(\"nan\")\n",
    "\n",
    "logger.info(\"Step0 ready.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c98f1-f862-4c78-8e7b-9d020bf9edd9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Step1：讀 CSV -> 篩術前 S -> 建 manifest\n",
    "# -----------------------------------------------------------------------------\n",
    "# 在這一段把資料先洗乾淨，做成一份可直接用的清單：\n",
    "# - outcome 只接受 0/1\n",
    "# - 檔名要符合命名規則\n",
    "# - 只保留術前 S\n",
    "# - wav 檔必須存在\n",
    "#\n",
    "# 最後會輸出 manifest_S_only.csv，後面流程都以它為準\n",
    "# =============================================================================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "need_cols = {\"sound.files\", \"outcome\"}\n",
    "missing = need_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV 缺欄位：{missing}；目前欄位={list(df.columns)}\")\n",
    "\n",
    "rows = []\n",
    "bad_names = 0\n",
    "missing_wav = 0\n",
    "filtered_not_S = 0\n",
    "bad_label = 0\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    wav_name = str(r[\"sound.files\"]).strip()\n",
    "\n",
    "    # 我只接受 outcome 是 0/1，其他值我直接跳過，避免標籤混亂\n",
    "    try:\n",
    "        label = int(r[\"outcome\"])\n",
    "    except Exception:\n",
    "        bad_label += 1\n",
    "        continue\n",
    "    if label not in (0, 1):\n",
    "        bad_label += 1\n",
    "        continue\n",
    "\n",
    "    info = parse_wav_name(wav_name)\n",
    "    if info is None:\n",
    "        bad_names += 1\n",
    "        continue\n",
    "\n",
    "    # 我只保留術前\n",
    "    if info[\"status\"] != USE_STATUS:\n",
    "        filtered_not_S += 1\n",
    "        continue\n",
    "\n",
    "    # 我確認 wav 檔真的存在\n",
    "    wav_path = AUDIO_DIR / wav_name\n",
    "    if not wav_path.exists():\n",
    "        missing_wav += 1\n",
    "        continue\n",
    "\n",
    "    rows.append({\n",
    "        \"wav_name\": wav_name,\n",
    "        \"wav_path\": str(wav_path),\n",
    "        \"patient_id\": info[\"patient_id\"],\n",
    "        \"status\": info[\"status\"],\n",
    "        \"vowel_id\": info[\"vowel_id\"],\n",
    "        \"clip_id\": info[\"clip_id\"],\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "df_m = (\n",
    "    pd.DataFrame(rows)\n",
    "      .sort_values([\"patient_id\", \"clip_id\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_m.to_csv(MANIFEST_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "seg_pos, seg_neg = count_pos_neg(df_m[\"label\"].values)\n",
    "pat_dist = df_m.drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict()\n",
    "\n",
    "logger.info(\"======== [Step1] Manifest built ========\")\n",
    "logger.info(f\"[Step1] CSV rows={len(df)}\")\n",
    "logger.info(f\"[Step1] bad filename format={bad_names}\")\n",
    "logger.info(f\"[Step1] bad label rows={bad_label} (non 0/1 or parse fail)\")\n",
    "logger.info(f\"[Step1] filtered_not_S={filtered_not_S} (只保留 status={USE_STATUS})\")\n",
    "logger.info(f\"[Step1] missing wav={missing_wav}\")\n",
    "logger.info(f\"[Step1] manifest segments={len(df_m)} | pos(1)={seg_pos} neg(0)={seg_neg} pos_rate={pos_rate(seg_pos, seg_neg):.4f}\")\n",
    "logger.info(f\"[Step1] unique patients={df_m['patient_id'].nunique()} | patient label dist={pat_dist}\")\n",
    "logger.info(f\"[Step1] saved: {MANIFEST_PATH}\")\n",
    "\n",
    "df_m.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d41421-61b1-4651-b26e-c7af4735a067",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step2：WAV -> Mel / STFT PNG\n",
    "# -----------------------------------------------------------------------------\n",
    "# 這一段把每個 wav 轉成兩張 PNG：\n",
    "# - Mel：比較像人耳的頻帶表示\n",
    "# - STFT：更原始的頻譜能量\n",
    "#\n",
    "# 特別處理短音檔：\n",
    "# - 會根據音檔長度調整 n_fft/hop，避免 n_fft 超過訊號長度\n",
    "# - 把時間軸固定到 TARGET_FRAMES，太短就用最後一欄延展補齊\n",
    "# - 用分位數決定顯示對比，避免整張圖變單色\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import librosa\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"缺少 librosa，請先安裝：pip install librosa\") from e\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 用這些門檻去過濾幾乎沒訊號的音檔\n",
    "# -------------------------\n",
    "SILENCE_STD_TH = 1e-6\n",
    "SILENCE_RMS_TH = 1e-6\n",
    "\n",
    "# 我用 dB 壓縮讓圖更穩定，TOP_DB 控制動態範圍\n",
    "TOP_DB = 80\n",
    "\n",
    "# 我準備一組保底的顯示範圍，避免對比太小導致整張單色\n",
    "VMIN_DB = -60\n",
    "VMAX_DB = 0\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 這一段是短音檔常用的頻譜參數\n",
    "# N_FFT 越大頻率解析越細，但短音檔越容易踩到長度不足\n",
    "# HOP 越小時間解析越密，但 frame 數會更多\n",
    "# N_MELS 決定 Mel 頻帶數量\n",
    "# TARGET_FRAMES 決定最後輸出統一的時間寬度\n",
    "# -------------------------\n",
    "N_FFT = 128\n",
    "HOP = 16\n",
    "N_MELS = 64\n",
    "TARGET_FRAMES = 64\n",
    "\n",
    "\n",
    "def load_audio_raw(path: str, sr=SR):\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    if y.size == 0:\n",
    "        return y\n",
    "    if not np.isfinite(y).all():\n",
    "        return np.array([], dtype=np.float32)\n",
    "\n",
    "    y = y.astype(np.float32)\n",
    "    y = y - np.mean(y)\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    y = y / peak\n",
    "    return y\n",
    "\n",
    "\n",
    "def is_silent(y: np.ndarray, std_th=SILENCE_STD_TH, rms_th=SILENCE_RMS_TH):\n",
    "    if y.size == 0:\n",
    "        return True, \"empty\"\n",
    "    if not np.isfinite(y).all():\n",
    "        return True, \"nan_or_inf\"\n",
    "    std = float(np.std(y))\n",
    "    rms = float(np.sqrt(np.mean(y ** 2)))\n",
    "    if std < std_th:\n",
    "        return True, f\"std<{std_th} (std={std:.2e})\"\n",
    "    if rms < rms_th:\n",
    "        return True, f\"rms<{rms_th} (rms={rms:.2e})\"\n",
    "    return False, \"ok\"\n",
    "\n",
    "\n",
    "def fix_frames(mat_2d: np.ndarray, target_frames: int = TARGET_FRAMES):\n",
    "    if mat_2d.ndim != 2:\n",
    "        raise ValueError(f\"fix_frames expects 2D matrix, got shape={mat_2d.shape}\")\n",
    "    T = mat_2d.shape[1]\n",
    "    if T == target_frames:\n",
    "        return mat_2d\n",
    "    if T > target_frames:\n",
    "        return mat_2d[:, :target_frames]\n",
    "\n",
    "    pad = target_frames - T\n",
    "    last_col = mat_2d[:, -1:]\n",
    "    pad_block = np.repeat(last_col, repeats=pad, axis=1)\n",
    "    return np.concatenate([mat_2d, pad_block], axis=1)\n",
    "\n",
    "\n",
    "def _robust_vmin_vmax(db_mat, default_vmin=VMIN_DB, default_vmax=VMAX_DB):\n",
    "    finite = db_mat[np.isfinite(db_mat)]\n",
    "    if finite.size == 0:\n",
    "        return default_vmin, default_vmax\n",
    "    vmin = float(np.percentile(finite, 5))\n",
    "    vmax = float(np.percentile(finite, 95))\n",
    "    if vmax - vmin < 10:\n",
    "        vmin = min(vmin, default_vmin)\n",
    "        vmax = max(vmax, default_vmax)\n",
    "    return vmin, vmax\n",
    "\n",
    "\n",
    "def _adapt_nfft_hop(y_len: int):\n",
    "    if y_len <= 0:\n",
    "        return N_FFT, HOP\n",
    "    n_fft = min(N_FFT, max(64, 2 ** int(np.floor(np.log2(y_len)))))\n",
    "    n_fft = min(n_fft, y_len)\n",
    "    hop = min(HOP, max(8, n_fft // 8))\n",
    "    return int(n_fft), int(hop)\n",
    "\n",
    "\n",
    "def save_mel_png(y, out_png: Path, sr=SR):\n",
    "    if y.size == 0:\n",
    "        return\n",
    "    n_fft, hop = _adapt_nfft_hop(len(y))\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=1.0, top_db=TOP_DB)\n",
    "    mel_db = fix_frames(mel_db, TARGET_FRAMES)\n",
    "    vmin, vmax = _robust_vmin_vmax(mel_db)\n",
    "\n",
    "    plt.figure(figsize=(4, 4), dpi=120)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mel_db, aspect=\"auto\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_stft_png(y, out_png: Path, sr=SR):\n",
    "    if y.size == 0:\n",
    "        return\n",
    "    n_fft, hop = _adapt_nfft_hop(len(y))\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop, win_length=n_fft, center=False)\n",
    "    mag = (np.abs(stft) ** 2).astype(np.float32)\n",
    "    spec_db = librosa.power_to_db(mag, ref=1.0, top_db=TOP_DB)\n",
    "    spec_db = fix_frames(spec_db, TARGET_FRAMES)\n",
    "    vmin, vmax = _robust_vmin_vmax(spec_db)\n",
    "\n",
    "    plt.figure(figsize=(4, 4), dpi=120)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(spec_db, aspect=\"auto\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "made = 0\n",
    "skipped_exist = 0\n",
    "skipped_silent = 0\n",
    "skipped_error = 0\n",
    "\n",
    "for _, r in df_m.iterrows():\n",
    "    wav_name = str(r[\"wav_name\"]).strip()\n",
    "    wav_path = str(r[\"wav_path\"]).strip()\n",
    "\n",
    "    mel_png  = MEL_PIC_DIR  / f\"{wav_name}.png\"\n",
    "    stft_png = STFT_PIC_DIR / f\"{wav_name}.png\"\n",
    "\n",
    "    if mel_png.exists() and stft_png.exists():\n",
    "        skipped_exist += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        y_raw = load_audio_raw(wav_path)\n",
    "        silent, reason = is_silent(y_raw)\n",
    "        if silent:\n",
    "            skipped_silent += 1\n",
    "            logger.info(f\"[Step2] skip silent/invalid wav: {wav_name} | reason={reason}\")\n",
    "            continue\n",
    "\n",
    "        save_mel_png(y_raw, mel_png)\n",
    "        save_stft_png(y_raw, stft_png)\n",
    "        made += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped_error += 1\n",
    "        logger.info(f\"[Step2] error on {wav_name}: {repr(e)}\")\n",
    "\n",
    "logger.info(\"======== [Step2] Images generated ========\")\n",
    "logger.info(f\"[Step2] made={made}\")\n",
    "logger.info(f\"[Step2] skipped(existing)={skipped_exist}\")\n",
    "logger.info(f\"[Step2] skipped(silent/invalid)={skipped_silent}\")\n",
    "logger.info(f\"[Step2] skipped(error)={skipped_error}\")\n",
    "logger.info(f\"[Step2] mel_dir={MEL_PIC_DIR} | count={len(list(MEL_PIC_DIR.glob('*.png')))}\")\n",
    "logger.info(f\"[Step2] stft_dir={STFT_PIC_DIR} | count={len(list(STFT_PIC_DIR.glob('*.png')))}\")\n",
    "\n",
    "step2_report = {\n",
    "    \"made\": made,\n",
    "    \"skipped_exist\": skipped_exist,\n",
    "    \"skipped_silent\": skipped_silent,\n",
    "    \"skipped_error\": skipped_error,\n",
    "    \"mel_count\": len(list(MEL_PIC_DIR.glob(\"*.png\"))),\n",
    "    \"stft_count\": len(list(STFT_PIC_DIR.glob(\"*.png\"))),\n",
    "    \"target_frames\": TARGET_FRAMES,\n",
    "    \"n_fft\": N_FFT,\n",
    "    \"hop\": HOP,\n",
    "    \"n_mels\": N_MELS\n",
    "}\n",
    "step2_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d71e5-0453-46fb-874c-e08f6bdf135d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step3：五折交叉驗證切分（Segment-level StratifiedKFold）\n",
    "# -----------------------------------------------------------------------------\n",
    "# 在這一段用分層切分，讓每一折的正負比例接近\n",
    "# 每折病人重疊數印出來，讓我知道重疊程度\n",
    "# =============================================================================\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def log_fold_distribution(fold: int, train_idx: np.ndarray, val_idx: np.ndarray,\n",
    "                          y_all: np.ndarray, df_meta: pd.DataFrame):\n",
    "    tr_pos, tr_neg = count_pos_neg(y_all[train_idx])\n",
    "    va_pos, va_neg = count_pos_neg(y_all[val_idx])\n",
    "\n",
    "    logger.info(f\"[Fold {fold}] SEG train: pos={tr_pos}, neg={tr_neg}, pos_rate={pos_rate(tr_pos, tr_neg):.4f}\")\n",
    "    logger.info(f\"[Fold {fold}] SEG  val : pos={va_pos}, neg={va_neg}, pos_rate={pos_rate(va_pos, va_neg):.4f}\")\n",
    "\n",
    "    tr_pat_dist = (df_meta.iloc[train_idx].drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict())\n",
    "    va_pat_dist = (df_meta.iloc[val_idx].drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict())\n",
    "\n",
    "    tr_pat_pos = int(tr_pat_dist.get(1, 0)); tr_pat_neg = int(tr_pat_dist.get(0, 0))\n",
    "    va_pat_pos = int(va_pat_dist.get(1, 0)); va_pat_neg = int(va_pat_dist.get(0, 0))\n",
    "\n",
    "    logger.info(f\"[Fold {fold}] PAT train: pos={tr_pat_pos}, neg={tr_pat_neg}, pos_rate={pos_rate(tr_pat_pos, tr_pat_neg):.4f} | dist={tr_pat_dist}\")\n",
    "    logger.info(f\"[Fold {fold}] PAT  val : pos={va_pat_pos}, neg={va_pat_neg}, pos_rate={pos_rate(va_pat_pos, va_pat_neg):.4f} | dist={va_pat_dist}\")\n",
    "\n",
    "\n",
    "def make_5fold_cv_splits_segment_stratified(y: np.ndarray, df_meta: pd.DataFrame,\n",
    "                                            n_folds: int = 5, seed: int = 42):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    all_idx = np.arange(len(y), dtype=int)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    splits = []\n",
    "    logger.info(\"======== [Step3] Start 5-fold CV split ========\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(all_idx, y), start=1):\n",
    "        logger.info(\"------------------------------------------------------------\")\n",
    "        logger.info(f\"[Fold {fold}] split created\")\n",
    "\n",
    "        inter = np.intersect1d(train_idx, val_idx)\n",
    "        if len(inter) != 0:\n",
    "            raise RuntimeError(f\"train/val overlap detected in fold {fold}: n={len(inter)}\")\n",
    "\n",
    "        log_fold_distribution(fold, train_idx, val_idx, y, df_meta)\n",
    "\n",
    "        tr_pats = set(df_meta.iloc[train_idx][\"patient_id\"].unique().tolist())\n",
    "        va_pats = set(df_meta.iloc[val_idx][\"patient_id\"].unique().tolist())\n",
    "        overlap_pats = tr_pats.intersection(va_pats)\n",
    "        logger.info(f\"[Fold {fold}] PAT overlap(train∩val)={len(overlap_pats)}\")\n",
    "\n",
    "        splits.append({\n",
    "            \"fold\": fold,\n",
    "            \"train_idx\": train_idx.astype(int),\n",
    "            \"val_idx\": val_idx.astype(int),\n",
    "        })\n",
    "\n",
    "    logger.info(\"======== [Step3] CV split finished ========\")\n",
    "    return splits\n",
    "\n",
    "\n",
    "y = df_m[\"label\"].to_numpy()\n",
    "splits = make_5fold_cv_splits_segment_stratified(\n",
    "    y=y,\n",
    "    df_meta=df_m,\n",
    "    n_folds=N_FOLDS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "logger.info(f\"[Step3] splits prepared: {len(splits)} folds\")\n",
    "logger.info(f\"[Step3] keys example: {list(splits[0].keys())}\")\n",
    "\n",
    "len(splits), splits[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5548c-c067-4693-a9a6-78bb62e4a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用已經做好的頻譜圖（Mel + STFT）來訓練一個雙輸入 CNN 模型，並用 segment-level 的五折分層交叉驗證評估。\n",
    "# 把每一折都跑出每個 epoch 的 Train/Val/Test 指標，並用驗證集的 AUROC_prob 來挑最佳 epoch。\n",
    "#\n",
    "# 處理的資料型態\n",
    "# - 輸入資料：CSV 內的 sound.files 與 outcome（0/1）\n",
    "# - 影像輸入：data/pic_v4/mel 與 data/pic_v4/stft 內的 png\n",
    "# - 模型輸出：二分類機率 prob（0~1）\n",
    "#\n",
    "# 會產出的檔案\n",
    "# - log：log_v4/run_v2_*.log\n",
    "# - 每折每 epoch 指標：data/out/csv/fold**_epoch_metrics.csv\n",
    "# - 每折最佳 epoch 指標：data/out/csv/fold**_best_metrics.csv\n",
    "# - 五折彙總（含 mean/std）：data/out/csv/cv_best_summary.csv\n",
    "# - 曲線圖：data/out/plots/fold**_(loss|acc|auroc).png\n",
    "# - 混淆矩陣：data/out/cm/fold**_cm_best.png\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5ee3d-4b2e-4695-8b75-7b5c62d7ba54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os, re, time, math\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Step0：把路徑、資料夾、logger、以及主要超參數集中在同一段\n",
    "# -----------------------------------------------------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "BASE_DIR = Path(\"/home/jovyan/114-1_HA\")\n",
    "\n",
    "DATA_DIR      = BASE_DIR / \"data\"\n",
    "CSV_PATH      = DATA_DIR / \"0604_final_REFCV.csv\"\n",
    "AUDIO_DIR     = DATA_DIR / \"a_slide\"     # 我這版不會用 wav 產圖，但仍保留檢查 wav 存在用\n",
    "PIC_DIR       = DATA_DIR / \"pic_v4\"      # 我用的頻譜圖版本\n",
    "MEL_PIC_DIR   = PIC_DIR / \"mel\"\n",
    "STFT_PIC_DIR  = PIC_DIR / \"stft\"\n",
    "\n",
    "# 所有輸出都統一丟到 out 底下，包含 csv、曲線圖、混淆矩陣\n",
    "OUT_DIR       = DATA_DIR / \"out\"\n",
    "CSV_OUT_DIR   = OUT_DIR / \"csv\"\n",
    "PLOT_DIR      = OUT_DIR / \"plots\"\n",
    "CM_DIR        = OUT_DIR / \"cm\"\n",
    "\n",
    "\n",
    "LOG_DIR       = BASE_DIR / \"log_v4\"\n",
    "\n",
    "# 先把會用到的資料夾都建起來，避免跑到一半才發現缺資料夾\n",
    "for d in [MEL_PIC_DIR, STFT_PIC_DIR, OUT_DIR, CSV_OUT_DIR, PLOT_DIR, CM_DIR, LOG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 把 Step1 的清單輸出固定成一個檔案，後面資料切分與訓練都以它為準\n",
    "MANIFEST_PATH = DATA_DIR / \"manifest_S_only.csv\"\n",
    "\n",
    "# 影像的輸入尺寸放在這裡，資料集讀圖時會用到\n",
    "IMG_H, IMG_W = 224, 224\n",
    "\n",
    "# 我用分層五折交叉驗證，seed 固定住讓切分可重現\n",
    "N_FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# 我把 Step4 的主要訓練設定放在這裡\n",
    "# warmup：先凍結 backbone，只訓練 head，讓分類頭先收斂\n",
    "# finetune：再解凍 backbone 後段，讓特徵更貼近資料分布\n",
    "EPOCHS_WARMUP   = 20\n",
    "EPOCHS_FINETUNE = 60\n",
    "BATCH_SIZE      = 32\n",
    "\n",
    "# warmup 的學習率我會設高一點讓 head 收斂快\n",
    "LR_WARMUP       = 3e-4\n",
    "\n",
    "# finetune 我用很低的學習率避免大幅破壞預訓練權重\n",
    "LR_FINETUNE     = 1e-5\n",
    "\n",
    "# 用 L2 來壓制 head 權重，降低過擬合\n",
    "WEIGHT_DECAY_L2 = 1e-4\n",
    "\n",
    "# 我用 dropout 讓 head 不要太快記住訓練集細節\n",
    "DROPOUT         = 0.35\n",
    "\n",
    "# head 的容量，我用它控制分類頭的表達能力\n",
    "HEAD_UNITS      = 64\n",
    "\n",
    "# early stopping 的耐心值，我用它決定多久沒進步就停\n",
    "PATIENCE        = 15\n",
    "\n",
    "# 在每折的 train 裡再切一個內層 val，用來 early stop 與挑 best epoch\n",
    "VAL_RATIO_IN_TRAIN = 0.15\n",
    "\n",
    "# 在驗證集上掃 threshold，找到讓 F1 最好的 cut point\n",
    "THR_SWEEP_STEPS = 201\n",
    "\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_PATH = LOG_DIR / f\"run_v2_{RUN_TAG}.log\"\n",
    "\n",
    "def build_logger(log_path: Path) -> logging.Logger:\n",
    "    logger = logging.getLogger(f\"voice_proj_{log_path.stem}\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = False\n",
    "    while logger.handlers:\n",
    "        logger.handlers.pop()\n",
    "\n",
    "    fmt = logging.Formatter(\n",
    "        fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "    fh = logging.FileHandler(log_path, mode=\"w\", encoding=\"utf-8\")\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(fmt)\n",
    "    logger.addHandler(sh)\n",
    "    return logger\n",
    "\n",
    "logger = build_logger(LOG_PATH)\n",
    "\n",
    "def count_pos_neg(y_arr):\n",
    "    y_arr = np.asarray(y_arr).astype(int)\n",
    "    n_pos = int((y_arr == 1).sum())\n",
    "    n_neg = int((y_arr == 0).sum())\n",
    "    return n_pos, n_neg\n",
    "\n",
    "def pos_rate(n_pos, n_neg):\n",
    "    total = n_pos + n_neg\n",
    "    return float(n_pos / total) if total > 0 else float(\"nan\")\n",
    "\n",
    "logger.info(\"==== Start run (v2) ====\")\n",
    "logger.info(f\"BASE_DIR={BASE_DIR}\")\n",
    "logger.info(f\"CSV_PATH={CSV_PATH}\")\n",
    "logger.info(f\"AUDIO_DIR={AUDIO_DIR}\")\n",
    "logger.info(f\"MEL_PIC_DIR={MEL_PIC_DIR}\")\n",
    "logger.info(f\"STFT_PIC_DIR={STFT_PIC_DIR}\")\n",
    "logger.info(f\"OUT_DIR={OUT_DIR}\")\n",
    "logger.info(f\"LOG_PATH={LOG_PATH}\")\n",
    "\n",
    "logger.info(\"==== Outputs will be saved to ====\")\n",
    "logger.info(f\"[LOG]   {LOG_PATH}\")\n",
    "logger.info(f\"[CSV]   per-epoch metrics: {CSV_OUT_DIR}/fold**_epoch_metrics.csv\")\n",
    "logger.info(f\"[CSV]   per-fold best:     {CSV_OUT_DIR}/fold**_best_metrics.csv\")\n",
    "logger.info(f\"[CSV]   cv summary:        {CSV_OUT_DIR}/cv_best_summary.csv\")\n",
    "logger.info(f\"[PLOT]  curves:           {PLOT_DIR}/fold**_(loss|acc|auroc).png\")\n",
    "logger.info(f\"[CM]    confusion:        {CM_DIR}/fold**_cm_best.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8790f-d97d-4bea-939b-bf12988cceed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step1：從 CSV 建一份乾淨的 manifest\n",
    "# -----------------------------------------------------------------------------\n",
    "# 這一步做三件事：\n",
    "# 1) 檢查 outcome 只接受 0/1\n",
    "# 2) 用檔名規則解析出 patient_id 等資訊\n",
    "# 3) 只保留術前資料（status = S），並確認 wav 檔存在\n",
    "# =============================================================================\n",
    "\n",
    "USE_STATUS = \"S\"\n",
    "\n",
    "FNAME_RE = re.compile(\n",
    "    r\"^(?P<pid>\\d+)_(?P<status>[SA])(?P<vowel>\\d+)_(?P<clip>\\d+)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_wav_name(fname: str):\n",
    "    m = FNAME_RE.match(fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    return {\n",
    "        \"patient_id\": int(m.group(\"pid\")),\n",
    "        \"status\": m.group(\"status\").upper(),\n",
    "        \"vowel_id\": int(m.group(\"vowel\")),\n",
    "        \"clip_id\": int(m.group(\"clip\")),\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "need_cols = {\"sound.files\", \"outcome\"}\n",
    "missing = need_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV 缺欄位：{missing}；目前欄位={list(df.columns)}\")\n",
    "\n",
    "rows = []\n",
    "bad_names = 0\n",
    "missing_wav = 0\n",
    "filtered_not_S = 0\n",
    "bad_label = 0\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    wav_name = str(r[\"sound.files\"]).strip()\n",
    "\n",
    "    # 我只允許 outcome 是 0 或 1，其他值我先排除，避免標籤污染\n",
    "    try:\n",
    "        label = int(r[\"outcome\"])\n",
    "    except Exception:\n",
    "        bad_label += 1\n",
    "        continue\n",
    "    if label not in (0, 1):\n",
    "        bad_label += 1\n",
    "        continue\n",
    "\n",
    "    info = parse_wav_name(wav_name)\n",
    "    if info is None:\n",
    "        bad_names += 1\n",
    "        continue\n",
    "\n",
    "    # 只拿術前 S，術後 A 先不進來\n",
    "    if info[\"status\"] != USE_STATUS:\n",
    "        filtered_not_S += 1\n",
    "        continue\n",
    "\n",
    "    # 檢查 wav 是否存在，避免 CSV 指到不存在的檔\n",
    "    wav_path = AUDIO_DIR / wav_name\n",
    "    if not wav_path.exists():\n",
    "        missing_wav += 1\n",
    "        continue\n",
    "\n",
    "    rows.append({\n",
    "        \"wav_name\": wav_name,\n",
    "        \"wav_path\": str(wav_path),\n",
    "        \"patient_id\": info[\"patient_id\"],\n",
    "        \"status\": info[\"status\"],\n",
    "        \"vowel_id\": info[\"vowel_id\"],\n",
    "        \"clip_id\": info[\"clip_id\"],\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "df_m = (\n",
    "    pd.DataFrame(rows)\n",
    "      .sort_values([\"patient_id\", \"clip_id\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_m.to_csv(MANIFEST_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "seg_pos, seg_neg = count_pos_neg(df_m[\"label\"].values)\n",
    "pat_dist = df_m.drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict()\n",
    "\n",
    "logger.info(\"======== [Step1] Manifest built ========\")\n",
    "logger.info(f\"[Step1] CSV rows={len(df)}\")\n",
    "logger.info(f\"[Step1] bad filename format={bad_names}\")\n",
    "logger.info(f\"[Step1] bad label rows={bad_label}\")\n",
    "logger.info(f\"[Step1] filtered_not_S={filtered_not_S} (keep status={USE_STATUS})\")\n",
    "logger.info(f\"[Step1] missing wav={missing_wav}\")\n",
    "logger.info(f\"[Step1] manifest segments={len(df_m)} | pos(1)={seg_pos} neg(0)={seg_neg} pos_rate={pos_rate(seg_pos, seg_neg):.4f}\")\n",
    "logger.info(f\"[Step1] unique patients={df_m['patient_id'].nunique()} | patient label dist={pat_dist}\")\n",
    "logger.info(f\"[Step1] saved: {MANIFEST_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f1b1c-029b-4898-bbac-dce16e35933f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step2：只做基本檢查，確認頻譜圖數量跟 manifest 對得上\n",
    "# -----------------------------------------------------------------------------\n",
    "# 這版不在這裡產圖，我假設 mel/stft png 已經在 pic_v4 裡準備好\n",
    "# 如果數量對不上，後面讀圖很可能會直接報錯\n",
    "# =============================================================================\n",
    "\n",
    "mel_count = len(list(MEL_PIC_DIR.glob(\"*.png\")))\n",
    "stft_count = len(list(STFT_PIC_DIR.glob(\"*.png\")))\n",
    "logger.info(\"======== [Step2] PNG count check ========\")\n",
    "logger.info(f\"[Step2] mel_count={mel_count}, stft_count={stft_count}, manifest={len(df_m)}\")\n",
    "if mel_count != len(df_m) or stft_count != len(df_m):\n",
    "    logger.info(\"[Step2] WARNING: png count mismatch, training may fail if missing images\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Step3：做 segment-level 的五折分層切分\n",
    "# -----------------------------------------------------------------------------\n",
    "# 目標是讓每一折 train/val 的正負比例接近\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "def log_fold_distribution(fold: int, train_idx: np.ndarray, val_idx: np.ndarray,\n",
    "                          y_all: np.ndarray, df_meta: pd.DataFrame):\n",
    "    tr_pos, tr_neg = count_pos_neg(y_all[train_idx])\n",
    "    va_pos, va_neg = count_pos_neg(y_all[val_idx])\n",
    "    logger.info(f\"[Fold {fold}] SEG train: pos={tr_pos}, neg={tr_neg}, pos_rate={pos_rate(tr_pos, tr_neg):.4f}\")\n",
    "    logger.info(f\"[Fold {fold}] SEG  val : pos={va_pos}, neg={va_neg}, pos_rate={pos_rate(va_pos, va_neg):.4f}\")\n",
    "\n",
    "    tr_pat_dist = (df_meta.iloc[train_idx].drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict())\n",
    "    va_pat_dist = (df_meta.iloc[val_idx].drop_duplicates(\"patient_id\")[\"label\"].value_counts().to_dict())\n",
    "    tr_pat_pos = int(tr_pat_dist.get(1, 0)); tr_pat_neg = int(tr_pat_dist.get(0, 0))\n",
    "    va_pat_pos = int(va_pat_dist.get(1, 0)); va_pat_neg = int(va_pat_dist.get(0, 0))\n",
    "    logger.info(f\"[Fold {fold}] PAT train: pos={tr_pat_pos}, neg={tr_pat_neg}, pos_rate={pos_rate(tr_pat_pos, tr_pat_neg):.4f} | dist={tr_pat_dist}\")\n",
    "    logger.info(f\"[Fold {fold}] PAT  val : pos={va_pat_pos}, neg={va_pat_neg}, pos_rate={pos_rate(va_pat_pos, va_pat_neg):.4f} | dist={va_pat_dist}\")\n",
    "\n",
    "def make_5fold_cv_splits_segment_stratified(y: np.ndarray, df_meta: pd.DataFrame,\n",
    "                                            n_folds: int = 5, seed: int = 42):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    all_idx = np.arange(len(y), dtype=int)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    splits = []\n",
    "    logger.info(\"======== [Step3] Start 5-fold CV split (Segment-level StratifiedKFold) ========\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(all_idx, y), start=1):\n",
    "        logger.info(\"------------------------------------------------------------\")\n",
    "        logger.info(f\"[Fold {fold}] split created\")\n",
    "\n",
    "        inter = np.intersect1d(train_idx, val_idx)\n",
    "        if len(inter) != 0:\n",
    "            raise RuntimeError(f\"train/val overlap detected in fold {fold}: n={len(inter)}\")\n",
    "\n",
    "        log_fold_distribution(fold, train_idx, val_idx, y, df_meta)\n",
    "\n",
    "        tr_pats = set(df_meta.iloc[train_idx][\"patient_id\"].unique().tolist())\n",
    "        va_pats = set(df_meta.iloc[val_idx][\"patient_id\"].unique().tolist())\n",
    "        overlap_pats = tr_pats.intersection(va_pats)\n",
    "        logger.info(f\"[Fold {fold}] PAT overlap(train∩val)={len(overlap_pats)}\")\n",
    "\n",
    "        splits.append({\"fold\": fold, \"train_idx\": train_idx.astype(int), \"val_idx\": val_idx.astype(int)})\n",
    "\n",
    "    logger.info(\"======== [Step3] CV split finished ========\")\n",
    "    return splits\n",
    "\n",
    "y_all = df_m[\"label\"].to_numpy()\n",
    "splits = make_5fold_cv_splits_segment_stratified(y=y_all, df_meta=df_m, n_folds=N_FOLDS, seed=SEED)\n",
    "logger.info(f\"[Step3] splits prepared: {len(splits)} folds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d82f8-275e-4e47-99d2-215e48782ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step4：我用雙輸入模型訓練並完整記錄每個 epoch 的 Train/Val/Test 指標\n",
    "# -----------------------------------------------------------------------------\n",
    "# 這一段做的事\n",
    "# - 用兩張圖（mel + stft）當作兩個輸入\n",
    "# - 兩個輸入共用同一個 EfficientNetB0 backbone\n",
    "# - 把圖片讀成灰階再 tile 成 3 通道，避免模型去學顏色映射造成的假紋理\n",
    "# - 用 class_weight 來處理類別不平衡，避免 batch 分布被硬扭成 50/50\n",
    "# - 每個 epoch 結束時，用 val 掃 threshold 找 F1 最佳的 thr，再把同一個 thr 套用到 train/test\n",
    "# - 我用 val_auroc_prob 來挑 best epoch，先把機率排序能力救起來，再談 F1\n",
    "# =============================================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input as effnet_preprocess\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 統一讀圖流程：png -> 灰階 -> resize -> 轉 float -> tile 三通道 -> EfficientNet 預處理\n",
    "# -----------------------------------------------------------------------------\n",
    "def _read_png_gray_as_3ch_preprocessed(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.resize(img, [IMG_H, IMG_W])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img3 = tf.tile(img, [1, 1, 3])\n",
    "    img3 = effnet_preprocess(img3)\n",
    "    return img3\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 只在訓練資料上做輕量增強，讓模型對亮度對比變化更穩\n",
    "# -----------------------------------------------------------------------------\n",
    "def _augment_img(img3):\n",
    "    img3 = tf.image.random_brightness(img3, max_delta=0.08)\n",
    "    img3 = tf.image.random_contrast(img3, lower=0.9, upper=1.1)\n",
    "    return img3\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 把 dataset 製作包成一個函式，方便不同 split 直接重用\n",
    "# training=True 時我會做增強，shuffle=True 時我會洗牌\n",
    "# -----------------------------------------------------------------------------\n",
    "def make_dataset(df_meta, idx, mel_dir, stft_dir, batch_size=32, training=False, shuffle=False, seed=42):\n",
    "    wav_names = df_meta.iloc[idx][\"wav_name\"].astype(str).tolist()\n",
    "    y = df_meta.iloc[idx][\"label\"].astype(int).to_numpy()\n",
    "\n",
    "    mel_paths = [str(Path(mel_dir) / f\"{w}.png\") for w in wav_names]\n",
    "    stft_paths = [str(Path(stft_dir) / f\"{w}.png\") for w in wav_names]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((mel_paths, stft_paths, y))\n",
    "\n",
    "    def _map(mel_p, stft_p, label):\n",
    "        mel = _read_png_gray_as_3ch_preprocessed(mel_p)\n",
    "        stft = _read_png_gray_as_3ch_preprocessed(stft_p)\n",
    "        if training:\n",
    "            mel = _augment_img(mel)\n",
    "            stft = _augment_img(stft)\n",
    "        return ({\"mel\": mel, \"stft\": stft}, tf.cast(label, tf.float32))\n",
    "\n",
    "    ds = ds.map(_map, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(idx), seed=seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 建雙輸入模型：兩支輸入共用一個 EfficientNetB0 backbone\n",
    "# 我用 GAP 把特徵變成向量，再串接，最後接一個小 head 做二分類\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_dual_shared_effnet(l2=1e-4, dropout=0.35, head_units=64):\n",
    "    mel_in  = keras.Input(shape=(IMG_H, IMG_W, 3), name=\"mel\")\n",
    "    stft_in = keras.Input(shape=(IMG_H, IMG_W, 3), name=\"stft\")\n",
    "\n",
    "    backbone = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(IMG_H, IMG_W, 3))\n",
    "    backbone.trainable = False\n",
    "\n",
    "    z_mel  = backbone(mel_in, training=False)\n",
    "    z_stft = backbone(stft_in, training=False)\n",
    "\n",
    "    z_mel  = layers.GlobalAveragePooling2D()(z_mel)\n",
    "    z_stft = layers.GlobalAveragePooling2D()(z_stft)\n",
    "\n",
    "    z = layers.Concatenate()([z_mel, z_stft])\n",
    "    z = layers.Dense(head_units, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2))(z)\n",
    "    z = layers.Dropout(dropout)(z)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\", name=\"prob\")(z)\n",
    "\n",
    "    model = keras.Model(inputs={\"mel\": mel_in, \"stft\": stft_in}, outputs=out, name=\"dual_effnet_shared\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 用這個函式控制 backbone 的可訓練狀態\n",
    "# warmup：整個 backbone 凍結\n",
    "# finetune：只解凍最後一段層，並把 BatchNorm 固定住，通常比較穩\n",
    "# -----------------------------------------------------------------------------\n",
    "def set_backbone_trainable(model, trainable: bool, unfreeze_ratio: float = 0.2):\n",
    "    backbone = None\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, keras.Model) and layer.name.startswith(\"efficientnet\"):\n",
    "            backbone = layer\n",
    "            break\n",
    "    if backbone is None:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, keras.Model) and \"efficientnet\" in layer.name:\n",
    "                backbone = layer\n",
    "                break\n",
    "    if backbone is None:\n",
    "        raise RuntimeError(\"Cannot find EfficientNet backbone inside the model.\")\n",
    "\n",
    "    if not trainable:\n",
    "        backbone.trainable = False\n",
    "        return\n",
    "\n",
    "    backbone.trainable = True\n",
    "    layers_all = backbone.layers\n",
    "    n = len(layers_all)\n",
    "    cut = int((1.0 - float(unfreeze_ratio)) * n)\n",
    "\n",
    "    for i, lyr in enumerate(layers_all):\n",
    "        if i < cut:\n",
    "            lyr.trainable = False\n",
    "        else:\n",
    "            if isinstance(lyr, layers.BatchNormalization):\n",
    "                lyr.trainable = False\n",
    "            else:\n",
    "                lyr.trainable = True\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 在驗證集上掃 threshold，找到讓 F1 最大的 cut point\n",
    "# -----------------------------------------------------------------------------\n",
    "def sweep_best_threshold(y_true, y_prob, steps=201):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "\n",
    "    thr_list = np.linspace(0.0, 1.0, steps)\n",
    "    best = {\"thr\": 0.5, \"f1\": -1.0, \"p\": 0.0, \"r\": 0.0}\n",
    "    eps = 1e-9\n",
    "\n",
    "    for thr in thr_list:\n",
    "        y_pred = (y_prob >= thr).astype(int)\n",
    "        tp = int(((y_pred == 1) & (y_true == 1)).sum())\n",
    "        fp = int(((y_pred == 1) & (y_true == 0)).sum())\n",
    "        fn = int(((y_pred == 0) & (y_true == 1)).sum())\n",
    "\n",
    "        p = tp / (tp + fp + eps)\n",
    "        r = tp / (tp + fn + eps)\n",
    "        f1 = 2 * p * r / (p + r + eps)\n",
    "\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best = {\"thr\": float(thr), \"f1\": float(f1), \"p\": float(p), \"r\": float(r)}\n",
    "    return best[\"thr\"], best[\"f1\"], best[\"p\"], best[\"r\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 把 model.predict 的輸出整理成 y_true 與 y_prob，方便後面統一算指標\n",
    "# -----------------------------------------------------------------------------\n",
    "def eval_probs(model, ds):\n",
    "    y_true_all, y_prob_all = [], []\n",
    "    for (x, y) in ds:\n",
    "        prob = model.predict(x, verbose=0).reshape(-1)\n",
    "        y_prob_all.append(prob)\n",
    "        y_true_all.append(y.numpy().reshape(-1))\n",
    "    y_true = np.concatenate(y_true_all).astype(int)\n",
    "    y_prob = np.concatenate(y_prob_all).astype(float)\n",
    "    return y_true, y_prob\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 用 best threshold 把機率轉成預測，再算 acc/precision/recall/f1/auroc 與混淆矩陣元素\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_metrics_from_probs(y_true, y_prob, thr):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    eps = 1e-9\n",
    "    tp = int(((y_pred == 1) & (y_true == 1)).sum())\n",
    "    tn = int(((y_pred == 0) & (y_true == 0)).sum())\n",
    "    fp = int(((y_pred == 1) & (y_true == 0)).sum())\n",
    "    fn = int(((y_pred == 0) & (y_true == 1)).sum())\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn + eps)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "\n",
    "    try:\n",
    "        auroc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auroc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"acc_bt\": float(acc),\n",
    "        \"precision_bt\": float(precision),\n",
    "        \"recall_bt\": float(recall),\n",
    "        \"f1_bt\": float(f1),\n",
    "        \"auroc_prob\": float(auroc),\n",
    "        \"thr\": float(thr),\n",
    "        \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 做一個 callback，每個 epoch 結束時都跑 train/val/test 的完整評估\n",
    "# 會把當下的結果塞進 out_rows，最後用它輸出成 per-epoch CSV\n",
    "# best epoch 的判斷我用 val_auroc_prob 最大化\n",
    "# -----------------------------------------------------------------------------\n",
    "class EpochFullEvalCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, fold, train_eval_ds, val_eval_ds, test_eval_ds, out_rows,\n",
    "                 thr_steps=201, best_monitor=\"val_auroc_prob\"):\n",
    "        super().__init__()\n",
    "        self.fold = fold\n",
    "        self.train_eval_ds = train_eval_ds\n",
    "        self.val_eval_ds = val_eval_ds\n",
    "        self.test_eval_ds = test_eval_ds\n",
    "        self.out_rows = out_rows\n",
    "        self.thr_steps = thr_steps\n",
    "        self.best_monitor = best_monitor\n",
    "        self.best_seen = -1e9\n",
    "        self.best_epoch = 0\n",
    "        self.best_snapshot = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        ep = int(epoch + 1)\n",
    "\n",
    "        yv_true, yv_prob = eval_probs(self.model, self.val_eval_ds)\n",
    "        best_thr, best_f1, best_p, best_r = sweep_best_threshold(yv_true, yv_prob, steps=self.thr_steps)\n",
    "\n",
    "        yt_true, yt_prob = eval_probs(self.model, self.train_eval_ds)\n",
    "        yte_true, yte_prob = eval_probs(self.model, self.test_eval_ds)\n",
    "\n",
    "        m_train = compute_metrics_from_probs(yt_true, yt_prob, best_thr)\n",
    "        m_val   = compute_metrics_from_probs(yv_true, yv_prob, best_thr)\n",
    "        m_test  = compute_metrics_from_probs(yte_true, yte_prob, best_thr)\n",
    "\n",
    "        row = {\"fold\": self.fold, \"epoch\": ep}\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            try:\n",
    "                row[k] = float(v)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        row.update({\n",
    "            \"best_thr_on_val\": float(best_thr),\n",
    "            \"val_best_f1\": float(best_f1),\n",
    "            \"val_best_p\": float(best_p),\n",
    "            \"val_best_r\": float(best_r),\n",
    "        })\n",
    "\n",
    "        for prefix, m in [(\"train\", m_train), (\"val\", m_val), (\"test\", m_test)]:\n",
    "            for k, v in m.items():\n",
    "                row[f\"{prefix}_{k}\"] = v\n",
    "\n",
    "        self.out_rows.append(row)\n",
    "\n",
    "        cur = row.get(self.best_monitor, None)\n",
    "        if cur is not None and np.isfinite(cur) and cur > self.best_seen:\n",
    "            self.best_seen = float(cur)\n",
    "            self.best_epoch = ep\n",
    "            self.best_snapshot = dict(row)\n",
    "\n",
    "        print(\n",
    "            f\"[Fold {self.fold}][Ep {ep:03d}] \"\n",
    "            f\"VAL(AUROC_prob={row.get('val_auroc_prob', float('nan')):.4f}, F1_bt={row.get('val_f1_bt', float('nan')):.4f}, thr={best_thr:.3f}) | \"\n",
    "            f\"TEST(AUROC_prob={row.get('test_auroc_prob', float('nan')):.4f}, F1_bt={row.get('test_f1_bt', float('nan')):.4f})\"\n",
    "        )\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 曲線圖與混淆矩陣輸出包成函式，讓每折做完直接存檔\n",
    "# -----------------------------------------------------------------------------\n",
    "def _safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def plot_curve(df_ep: pd.DataFrame, fold: int, metric: str, out_png: Path):\n",
    "    x = df_ep[\"epoch\"].astype(int).to_numpy()\n",
    "    y_tr = df_ep[metric].apply(_safe_float).to_numpy() if metric in df_ep.columns else None\n",
    "    y_va = df_ep[f\"val_{metric}\"].apply(_safe_float).to_numpy() if f\"val_{metric}\" in df_ep.columns else None\n",
    "\n",
    "    plt.figure()\n",
    "    if y_tr is not None:\n",
    "        plt.plot(x, y_tr, label=f\"train_{metric}\")\n",
    "    if y_va is not None:\n",
    "        plt.plot(x, y_va, label=f\"val_{metric}\")\n",
    "    plt.title(f\"Fold {fold} {metric}\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    if metric in (\"acc\", \"auroc\"):\n",
    "        plt.ylim(0.0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "def save_confusion_matrix_png(y_true: np.ndarray, y_prob: np.ndarray, thr: float, out_png: Path, fold: int):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = (np.asarray(y_prob) >= float(thr)).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(f\"Fold {fold} Confusion Matrix (thr={thr:.3f})\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.ylabel(\"True\")\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.xticks([0, 1], [\"0\", \"1\"])\n",
    "    plt.yticks([0, 1], [\"0\", \"1\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 開始跑五折\n",
    "# -----------------------------------------------------------------------------\n",
    "# 把 Step3 的 val_idx 當作外層測試集 test\n",
    "# 然後再從 train_idx 裡切一個內層 val，用來 early stopping 與挑 best epoch\n",
    "# =============================================================================\n",
    "\n",
    "all_best_rows = []\n",
    "\n",
    "for sp in splits:\n",
    "    fold = sp[\"fold\"]\n",
    "    train_idx_full = sp[\"train_idx\"]\n",
    "    test_idx = sp[\"val_idx\"]\n",
    "\n",
    "    y_train_full = df_m.iloc[train_idx_full][\"label\"].astype(int).to_numpy()\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_RATIO_IN_TRAIN, random_state=SEED + fold)\n",
    "    tr_sub, va_sub = next(sss.split(np.zeros(len(train_idx_full)), y_train_full))\n",
    "    tr_idx = train_idx_full[tr_sub]\n",
    "    val_idx = train_idx_full[va_sub]\n",
    "\n",
    "    tr_pos, tr_neg = count_pos_neg(df_m.iloc[tr_idx][\"label\"].values)\n",
    "    va_pos, va_neg = count_pos_neg(df_m.iloc[val_idx][\"label\"].values)\n",
    "    te_pos, te_neg = count_pos_neg(df_m.iloc[test_idx][\"label\"].values)\n",
    "\n",
    "    logger.info(\"------------------------------------------------------------\")\n",
    "    logger.info(f\"[Step4][Fold {fold}] split for Step4 (train/val/test)\")\n",
    "    logger.info(f\"[Fold {fold}] TRAIN seg: pos={tr_pos}, neg={tr_neg}, pos_rate={pos_rate(tr_pos, tr_neg):.4f}\")\n",
    "    logger.info(f\"[Fold {fold}] VAL   seg: pos={va_pos}, neg={va_neg}, pos_rate={pos_rate(va_pos, va_neg):.4f}\")\n",
    "    logger.info(f\"[Fold {fold}] TEST  seg: pos={te_pos}, neg={te_neg}, pos_rate={pos_rate(te_pos, te_neg):.4f}\")\n",
    "\n",
    "    train_ds = make_dataset(df_m, tr_idx,  MEL_PIC_DIR, STFT_PIC_DIR, batch_size=BATCH_SIZE,\n",
    "                            training=True, shuffle=True, seed=SEED + fold)\n",
    "    val_ds   = make_dataset(df_m, val_idx, MEL_PIC_DIR, STFT_PIC_DIR, batch_size=BATCH_SIZE,\n",
    "                            training=False, shuffle=False)\n",
    "    test_ds  = make_dataset(df_m, test_idx, MEL_PIC_DIR, STFT_PIC_DIR, batch_size=BATCH_SIZE,\n",
    "                            training=False, shuffle=False)\n",
    "\n",
    "    train_eval_ds = make_dataset(df_m, tr_idx,  MEL_PIC_DIR, STFT_PIC_DIR, batch_size=BATCH_SIZE,\n",
    "                                 training=False, shuffle=False)\n",
    "\n",
    "    # 我用 class_weight 來提升少數類的損失權重\n",
    "    # 這份資料 pos 比較多，所以我會提高類別 0 的權重，逼模型不要一直偏向猜 1\n",
    "    w0 = float(tr_pos / max(tr_neg, 1))\n",
    "    w1 = 1.0\n",
    "    class_weight = {0: w0, 1: w1}\n",
    "    logger.info(f\"[Fold {fold}] class_weight={class_weight}\")\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_dual_shared_effnet(l2=WEIGHT_DECAY_L2, dropout=DROPOUT, head_units=HEAD_UNITS)\n",
    "\n",
    "    epoch_rows = []\n",
    "    cb_full = EpochFullEvalCallback(\n",
    "        fold=fold,\n",
    "        train_eval_ds=train_eval_ds,\n",
    "        val_eval_ds=val_ds,\n",
    "        test_eval_ds=test_ds,\n",
    "        out_rows=epoch_rows,\n",
    "        thr_steps=THR_SWEEP_STEPS,\n",
    "        best_monitor=\"val_auroc_prob\"\n",
    "    )\n",
    "\n",
    "    cb_es = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auroc\", mode=\"max\",\n",
    "        patience=PATIENCE, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "\n",
    "    # 我先做 warmup：backbone 全凍結，只訓練 head\n",
    "    set_backbone_trainable(model, trainable=False)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LR_WARMUP),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.05),\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "            keras.metrics.AUC(name=\"auroc\"),\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "        ]\n",
    "    )\n",
    "    logger.info(f\"[Fold {fold}] Stage1 warmup start: epochs={EPOCHS_WARMUP}, LR={LR_WARMUP}, backbone frozen\")\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS_WARMUP,\n",
    "        callbacks=[cb_full, cb_es],\n",
    "        class_weight=class_weight,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 我再做 finetune：只解凍 backbone 最後一段，BatchNorm 固定不動\n",
    "    set_backbone_trainable(model, trainable=True, unfreeze_ratio=0.2)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LR_FINETUNE),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.05),\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "            keras.metrics.AUC(name=\"auroc\"),\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "        ]\n",
    "    )\n",
    "    logger.info(f\"[Fold {fold}] Stage2 finetune start: epochs={EPOCHS_FINETUNE}, LR={LR_FINETUNE}, unfreeze_ratio=0.2\")\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS_WARMUP + EPOCHS_FINETUNE,\n",
    "        initial_epoch=EPOCHS_WARMUP,\n",
    "        callbacks=[cb_full, cb_es],\n",
    "        class_weight=class_weight,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    df_ep = pd.DataFrame(epoch_rows)\n",
    "    ep_csv = CSV_OUT_DIR / f\"fold{fold:02d}_epoch_metrics.csv\"\n",
    "    df_ep.to_csv(ep_csv, index=False, encoding=\"utf-8\")\n",
    "    logger.info(f\"[Fold {fold}] saved per-epoch metrics: {ep_csv}\")\n",
    "\n",
    "    # 我用 val_auroc_prob 最大的那個 epoch 當 best\n",
    "    if cb_full.best_snapshot is None:\n",
    "        best_idx = pd.to_numeric(df_ep[\"val_auroc_prob\"], errors=\"coerce\").idxmax()\n",
    "        best_row = df_ep.loc[best_idx].to_dict()\n",
    "        best_epoch = int(best_row.get(\"epoch\", -1))\n",
    "    else:\n",
    "        best_row = dict(cb_full.best_snapshot)\n",
    "        best_epoch = int(cb_full.best_epoch)\n",
    "\n",
    "    best_row[\"best_by\"] = \"val_auroc_prob\"\n",
    "    best_row[\"best_epoch\"] = best_epoch\n",
    "\n",
    "    best_csv = CSV_OUT_DIR / f\"fold{fold:02d}_best_metrics.csv\"\n",
    "    pd.DataFrame([best_row]).to_csv(best_csv, index=False, encoding=\"utf-8\")\n",
    "    logger.info(f\"[Fold {fold}] saved best metrics: {best_csv}\")\n",
    "\n",
    "    # 把最佳權重存起來，方便之後做重現或 Grad-CAM\n",
    "    w_path = OUT_DIR / f\"fold{fold:02d}_best_by_valauroc_epoch{best_epoch:03d}.weights.h5\"\n",
    "    model.save_weights(w_path)\n",
    "    logger.info(f\"[Fold {fold}] saved weights: {w_path}\")\n",
    "\n",
    "    plot_curve(df_ep, fold, \"loss\",  PLOT_DIR / f\"fold{fold:02d}_loss.png\")\n",
    "    plot_curve(df_ep, fold, \"acc\",   PLOT_DIR / f\"fold{fold:02d}_acc.png\")\n",
    "    plot_curve(df_ep, fold, \"auroc\", PLOT_DIR / f\"fold{fold:02d}_auroc.png\")\n",
    "    logger.info(f\"[Fold {fold}] saved curves: {PLOT_DIR}/fold{fold:02d}_(loss|acc|auroc).png\")\n",
    "\n",
    "    # 用驗證集找到的 best threshold，回到 test 產混淆矩陣\n",
    "    best_thr = float(best_row.get(\"best_thr_on_val\", 0.5))\n",
    "    model.load_weights(w_path)\n",
    "\n",
    "    yte_true, yte_prob = eval_probs(model, test_ds)\n",
    "    cm_png = CM_DIR / f\"fold{fold:02d}_cm_best.png\"\n",
    "    save_confusion_matrix_png(yte_true, yte_prob, best_thr, cm_png, fold)\n",
    "    logger.info(f\"[Fold {fold}] saved confusion matrix: {cm_png}\")\n",
    "\n",
    "    all_best_rows.append(best_row)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 五折彙總：把每折 best 指標合併，並算 mean/std\n",
    "# =============================================================================\n",
    "\n",
    "df_best = pd.DataFrame(all_best_rows)\n",
    "\n",
    "num_cols = []\n",
    "for c in df_best.columns:\n",
    "    if c in [\"fold\", \"epoch\", \"best_epoch\"]:\n",
    "        continue\n",
    "    s = pd.to_numeric(df_best[c], errors=\"coerce\")\n",
    "    if s.notna().sum() > 0:\n",
    "        num_cols.append(c)\n",
    "\n",
    "mean_row = {\"fold\": \"mean\"}\n",
    "std_row  = {\"fold\": \"std\"}\n",
    "for c in num_cols:\n",
    "    vals = pd.to_numeric(df_best[c], errors=\"coerce\")\n",
    "    mean_row[c] = float(np.nanmean(vals))\n",
    "    std_row[c]  = float(np.nanstd(vals))\n",
    "\n",
    "df_sum = pd.concat([df_best, pd.DataFrame([mean_row, std_row])], ignore_index=True)\n",
    "\n",
    "summary_csv = CSV_OUT_DIR / \"cv_best_summary.csv\"\n",
    "df_sum.to_csv(summary_csv, index=False, encoding=\"utf-8\")\n",
    "logger.info(f\"[CV] saved summary: {summary_csv}\")\n",
    "\n",
    "print(\"\\n========== CV BEST SUMMARY (tail) ==========\")\n",
    "print(df_sum.tail(7))\n",
    "print(\"\\n[Done] Outputs:\")\n",
    "print(f\"- Log: {LOG_PATH}\")\n",
    "print(f\"- Per-epoch CSV: {CSV_OUT_DIR}/fold**_epoch_metrics.csv\")\n",
    "print(f\"- Per-fold best CSV: {CSV_OUT_DIR}/fold**_best_metrics.csv\")\n",
    "print(f\"- CV summary CSV: {summary_csv}\")\n",
    "print(f\"- Curves: {PLOT_DIR}/fold**_(loss|acc|auroc).png\")\n",
    "print(f\"- Confusion Matrix: {CM_DIR}/fold**_cm_best.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "440e84f4-05d7-40e3-8d9d-959cfb120766",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>train_pos</th>\n",
       "      <th>train_neg</th>\n",
       "      <th>train_pos_rate</th>\n",
       "      <th>train_pos:neg</th>\n",
       "      <th>val_pos</th>\n",
       "      <th>val_neg</th>\n",
       "      <th>val_pos_rate</th>\n",
       "      <th>val_pos:neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>200:130</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>60:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>210</td>\n",
       "      <td>130</td>\n",
       "      <td>0.6176</td>\n",
       "      <td>210:130</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>50:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>140</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>210:140</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>210</td>\n",
       "      <td>140</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>210:140</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>140</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>210:140</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>50:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  train_pos  train_neg  train_pos_rate train_pos:neg  val_pos  val_neg  \\\n",
       "0     1        200        130          0.6061       200:130       60       40   \n",
       "1     2        210        130          0.6176       210:130       50       40   \n",
       "2     3        210        140          0.6000       210:140       50       30   \n",
       "3     4        210        140          0.6000       210:140       50       30   \n",
       "4     5        210        140          0.6000       210:140       50       30   \n",
       "\n",
       "   val_pos_rate val_pos:neg  \n",
       "0        0.6000       60:40  \n",
       "1        0.5556       50:40  \n",
       "2        0.6250       50:30  \n",
       "3        0.6250       50:30  \n",
       "4        0.6250       50:30  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def summarize_fold_ratios(df_m, splits):\n",
    "    y_all = df_m[\"label\"].to_numpy().astype(int)\n",
    "\n",
    "    rows = []\n",
    "    for s in splits:\n",
    "        fold = s[\"fold\"]\n",
    "        tr = s[\"train_idx\"]\n",
    "        va = s[\"val_idx\"]\n",
    "\n",
    "        tr_pos = int((y_all[tr] == 1).sum())\n",
    "        tr_neg = int((y_all[tr] == 0).sum())\n",
    "        tr_rate = tr_pos / (tr_pos + tr_neg) if (tr_pos + tr_neg) > 0 else np.nan\n",
    "\n",
    "        va_pos = int((y_all[va] == 1).sum())\n",
    "        va_neg = int((y_all[va] == 0).sum())\n",
    "        va_rate = va_pos / (va_pos + va_neg) if (va_pos + va_neg) > 0 else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"fold\": fold,\n",
    "            \"train_pos\": tr_pos,\n",
    "            \"train_neg\": tr_neg,\n",
    "            \"train_pos_rate\": round(tr_rate, 4),\n",
    "            \"train_pos:neg\": f\"{tr_pos}:{tr_neg}\",\n",
    "            \"val_pos\": va_pos,\n",
    "            \"val_neg\": va_neg,\n",
    "            \"val_pos_rate\": round(va_rate, 4),\n",
    "            \"val_pos:neg\": f\"{va_pos}:{va_neg}\",\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"fold\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "tbl = summarize_fold_ratios(df_m, splits)\n",
    "tbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcec150-3fdc-41fb-aad0-6114f59288fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d01a97-bfe7-4454-9fcf-b9652e7659a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3ab7f-635f-4b38-afbd-67e6c8e40bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c01d1-0c55-4cd8-a5d5-175d585ce10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb6354-2185-4567-913b-13bbdbf052e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76edd7-1db7-4980-87d5-959b3c1620aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# explain_cam.py  (Keras 3 compatible / Restricted to 5 yellow weights)\n",
    "# =============================================================================\n",
    "# 只跑指定的 5 個 best_by_valauroc 權重檔，避免誤讀到其他版本的權重造成結果混亂\n",
    "# Grad-CAM 分別對 mel / stft 產熱區，再做 ΔCAM 方便看兩個分支的注意力差異\n",
    "# Keras 3 下 load_weights 不支援 by_name，權重必須完全對齊，模型結構因此刻意保持訓練同款\n",
    "#\n",
    "# 依賴：\n",
    "# - /home/jovyan/114-1_HA/data/manifest_S_only.csv\n",
    "# - /home/jovyan/114-1_HA/data/pic_v4/mel/*.png\n",
    "# - /home/jovyan/114-1_HA/data/pic_v4/stft/*.png\n",
    "# - /home/jovyan/114-1_HA/data/out/csv/fold**_best_metrics.csv\n",
    "# - /home/jovyan/114-1_HA/data/out/fold**_best_by_valauroc_epochXXX.weights.h5\n",
    "#\n",
    "# 輸出：\n",
    "# - /home/jovyan/114-1_HA/data/out/explain/cam/fold**/*__mel_cam.png\n",
    "# - /home/jovyan/114-1_HA/data/out/explain/cam/fold**/*__stft_cam.png\n",
    "# - /home/jovyan/114-1_HA/data/out/explain/cam/fold**/*__dcam.png\n",
    "# - /home/jovyan/114-1_HA/data/out/explain/cam/cam_index.csv\n",
    "# - /home/jovyan/114-1_HA/log_explain/explain_cam_*.log\n",
    "# =============================================================================\n",
    "\n",
    "import re, time, logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input as effnet_preprocess\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 0) 全域設定\n",
    "# =============================================================================\n",
    "BASE_DIR = Path(\"/home/jovyan/114-1_HA\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "MANIFEST_PATH = DATA_DIR / \"manifest_S_only.csv\"\n",
    "PIC_DIR       = DATA_DIR / \"pic_v4\"\n",
    "MEL_DIR       = PIC_DIR / \"mel\"\n",
    "STFT_DIR      = PIC_DIR / \"stft\"\n",
    "\n",
    "OUT_DIR       = DATA_DIR / \"out\"\n",
    "BEST_CSV_DIR  = OUT_DIR / \"csv\"\n",
    "\n",
    "EXPL_DIR      = OUT_DIR / \"explain\" / \"cam\"\n",
    "EXPL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_H, IMG_W = 224, 224\n",
    "\n",
    "# 指定的 5 個權重檔名，檔名固定才能精準對到每折的最佳 epoch\n",
    "ALLOWED_WEIGHTS = [\n",
    "    \"fold01_best_by_valauroc_epoch031.weights.h5\",\n",
    "    \"fold02_best_by_valauroc_epoch079.weights.h5\",\n",
    "    \"fold03_best_by_valauroc_epoch080.weights.h5\",\n",
    "    \"fold04_best_by_valauroc_epoch080.weights.h5\",\n",
    "    \"fold05_best_by_valauroc_epoch080.weights.h5\",\n",
    "]\n",
    "\n",
    "# 每種 TP/TN/FP/FN 各抽幾張\n",
    "# 常見現象：模型偏猜 1 時，TN/FN 可能幾乎消失，抽樣會直接抽不到\n",
    "K_PER_CASE = 10\n",
    "\n",
    "DEFAULT_THR = 0.5\n",
    "\n",
    "# 抽不到某類時用機率排序補齊，避免整折沒有圖可看\n",
    "# 小插曲：很多時候反而是這個補齊機制最先暴露校準問題\n",
    "FALLBACK_PROB_RANKING = True\n",
    "\n",
    "INFER_LOG_EVERY  = 25\n",
    "RENDER_LOG_EVERY = 5\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# logger（主控台 + 檔案）\n",
    "# =============================================================================\n",
    "LOG_DIR = BASE_DIR / \"log_explain\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_PATH = LOG_DIR / f\"explain_cam_{RUN_TAG}.log\"\n",
    "\n",
    "def build_logger(log_path: Path):\n",
    "    logger = logging.getLogger(log_path.stem)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = False\n",
    "    while logger.handlers:\n",
    "        logger.handlers.pop()\n",
    "\n",
    "    fmt = logging.Formatter(\n",
    "        \"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "    fh = logging.FileHandler(log_path, mode=\"w\", encoding=\"utf-8\")\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(fmt)\n",
    "    logger.addHandler(sh)\n",
    "    return logger\n",
    "\n",
    "logger = build_logger(LOG_PATH)\n",
    "logger.info(\"==== Start explain_cam.py (restricted 5 weights / Keras3) ====\")\n",
    "logger.info(f\"LOG_PATH={LOG_PATH}\")\n",
    "logger.info(f\"MANIFEST_PATH={MANIFEST_PATH}\")\n",
    "logger.info(f\"MEL_DIR={MEL_DIR}\")\n",
    "logger.info(f\"STFT_DIR={STFT_DIR}\")\n",
    "logger.info(f\"BEST_CSV_DIR={BEST_CSV_DIR}\")\n",
    "logger.info(f\"EXPL_DIR={EXPL_DIR}\")\n",
    "logger.info(\"==== Allowed weights (ONLY these 5) ====\")\n",
    "for w in ALLOWED_WEIGHTS:\n",
    "    logger.info(f\"  - {OUT_DIR / w}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1) 與訓練一致的讀圖（灰階 -> tile -> EfficientNet preprocess）\n",
    "# =============================================================================\n",
    "def read_png_gray_as_3ch_preprocessed(path: tf.Tensor) -> tf.Tensor:\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.resize(img, [IMG_H, IMG_W])\n",
    "    img = tf.cast(img, tf.float32)          # 0..255\n",
    "    img3 = tf.tile(img, [1, 1, 3])          # 1ch -> 3ch\n",
    "    img3 = effnet_preprocess(img3)\n",
    "    return img3\n",
    "\n",
    "def make_single_input(mel_png: str, stft_png: str):\n",
    "    mel  = read_png_gray_as_3ch_preprocessed(tf.constant(mel_png))\n",
    "    stft = read_png_gray_as_3ch_preprocessed(tf.constant(stft_png))\n",
    "    x = {\"mel\": tf.expand_dims(mel, 0), \"stft\": tf.expand_dims(stft, 0)}\n",
    "    return x, mel, stft\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) 訓練同款模型（避免 weights 對不上）\n",
    "# =============================================================================\n",
    "def build_dual_shared_effnet_train_like(l2=1e-4, dropout=0.35, head_units=64):\n",
    "    mel_in  = keras.Input(shape=(IMG_H, IMG_W, 3), name=\"mel\")\n",
    "    stft_in = keras.Input(shape=(IMG_H, IMG_W, 3), name=\"stft\")\n",
    "\n",
    "    backbone = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_H, IMG_W, 3)\n",
    "    )\n",
    "    backbone.trainable = False\n",
    "\n",
    "    z_mel  = backbone(mel_in, training=False)\n",
    "    z_stft = backbone(stft_in, training=False)\n",
    "\n",
    "    # 兩個 GAP 的 input 直接當 CAM 的 feature map\n",
    "    # 小發現：拿 GAP 的 output 做 CAM 會完全變成常數向量，熱圖會像是在敷衍\n",
    "    z_mel_gap  = layers.GlobalAveragePooling2D(name=\"mel_gap\")(z_mel)\n",
    "    z_stft_gap = layers.GlobalAveragePooling2D(name=\"stft_gap\")(z_stft)\n",
    "\n",
    "    z = layers.Concatenate(name=\"concat\")([z_mel_gap, z_stft_gap])\n",
    "    z = layers.Dense(\n",
    "        head_units,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=keras.regularizers.l2(l2),\n",
    "        name=\"head_dense\"\n",
    "    )(z)\n",
    "    z = layers.Dropout(dropout, name=\"head_dropout\")(z)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\", name=\"prob\")(z)\n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs={\"mel\": mel_in, \"stft\": stft_in},\n",
    "        outputs=out,\n",
    "        name=\"dual_effnet_shared\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def set_backbone_trainable(model, trainable: bool, unfreeze_ratio: float = 0.2):\n",
    "    # 結構對齊用途，推論階段其實凍結也能產 CAM\n",
    "    backbone = None\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, keras.Model) and (\"efficientnet\" in layer.name):\n",
    "            backbone = layer\n",
    "            break\n",
    "    if backbone is None:\n",
    "        raise RuntimeError(\"Cannot find EfficientNet backbone inside the model.\")\n",
    "\n",
    "    if not trainable:\n",
    "        backbone.trainable = False\n",
    "        return\n",
    "\n",
    "    backbone.trainable = True\n",
    "    layers_all = backbone.layers\n",
    "    n = len(layers_all)\n",
    "    cut = int((1.0 - float(unfreeze_ratio)) * n)\n",
    "\n",
    "    for i, lyr in enumerate(layers_all):\n",
    "        if i < cut:\n",
    "            lyr.trainable = False\n",
    "        else:\n",
    "            if isinstance(lyr, layers.BatchNormalization):\n",
    "                lyr.trainable = False\n",
    "            else:\n",
    "                lyr.trainable = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) CAM models（抓 mel_gap/stft_gap 的 input 當 feature map）\n",
    "# =============================================================================\n",
    "def build_cam_models(model: keras.Model):\n",
    "    mel_feat  = model.get_layer(\"mel_gap\").input\n",
    "    stft_feat = model.get_layer(\"stft_gap\").input\n",
    "    prob = model.output\n",
    "\n",
    "    cam_model_mel  = keras.Model(inputs=model.inputs, outputs=[mel_feat, prob],  name=\"cam_model_mel\")\n",
    "    cam_model_stft = keras.Model(inputs=model.inputs, outputs=[stft_feat, prob], name=\"cam_model_stft\")\n",
    "\n",
    "    logger.info(f\"[CAM] mel_feat shape  = {mel_feat.shape}\")\n",
    "    logger.info(f\"[CAM] stft_feat shape = {stft_feat.shape}\")\n",
    "    return cam_model_mel, cam_model_stft\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) Grad-CAM\n",
    "# =============================================================================\n",
    "def grad_cam(cam_model: keras.Model, x_dict: dict) -> (np.ndarray, float):\n",
    "    # cam_model outputs: [feature_map, prob]\n",
    "    # returns: cam(224,224) 0..1, prob float\n",
    "    with tf.GradientTape() as tape:\n",
    "        feat, prob = cam_model(x_dict, training=False)\n",
    "        prob_scalar = prob[:, 0]\n",
    "        tape.watch(feat)\n",
    "\n",
    "    grads = tape.gradient(prob_scalar, feat)\n",
    "    if grads is None:\n",
    "        # 稀有但致命：通常是 feature map 與 prob 不在同一張圖\n",
    "        raise RuntimeError(\"Gradients are None (graph disconnected).\")\n",
    "\n",
    "    weights = tf.reduce_mean(grads, axis=(1, 2))\n",
    "    cam = tf.reduce_sum(feat * weights[:, None, None, :], axis=-1)\n",
    "    cam = tf.nn.relu(cam)\n",
    "\n",
    "    cam = cam[0]\n",
    "    cam = cam / (tf.reduce_max(cam) + 1e-9)\n",
    "\n",
    "    cam = tf.image.resize(cam[..., None], [IMG_H, IMG_W])\n",
    "    cam = tf.squeeze(cam, axis=-1).numpy()\n",
    "    return cam.astype(np.float32), float(prob_scalar.numpy()[0])\n",
    "\n",
    "def overlay_cam_on_image(img3: tf.Tensor, cam01: np.ndarray, alpha=0.45):\n",
    "    base = img3.numpy().astype(np.float32)\n",
    "    base = base - base.min()\n",
    "    base = base / (base.max() + 1e-9)\n",
    "\n",
    "    plt.figure(figsize=(4.2, 4.2))\n",
    "    plt.imshow(base)\n",
    "    plt.imshow(cam01, alpha=alpha)\n",
    "    plt.axis(\"off\")\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) 資料與推論工具\n",
    "# =============================================================================\n",
    "def load_manifest():\n",
    "    if not MANIFEST_PATH.exists():\n",
    "        raise FileNotFoundError(f\"manifest not found: {MANIFEST_PATH}\")\n",
    "    dfm = pd.read_csv(MANIFEST_PATH)\n",
    "    need = {\"wav_name\", \"patient_id\", \"label\"}\n",
    "    miss = need - set(dfm.columns)\n",
    "    if miss:\n",
    "        raise ValueError(f\"manifest missing cols: {miss}, cols={list(dfm.columns)}\")\n",
    "    return dfm\n",
    "\n",
    "def rebuild_fold_test_indices(dfm: pd.DataFrame):\n",
    "    # Segment-level StratifiedKFold，shuffle=True + random_state=42\n",
    "    y_all = dfm[\"label\"].astype(int).to_numpy()\n",
    "    all_idx = np.arange(len(y_all), dtype=int)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_to_test = {}\n",
    "    for f, (_, va) in enumerate(skf.split(all_idx, y_all), start=1):\n",
    "        fold_to_test[f] = va.astype(int)\n",
    "    return fold_to_test\n",
    "\n",
    "def infer_probs_for_indices(model, dfm: pd.DataFrame, idx: np.ndarray):\n",
    "    y_true = dfm.iloc[idx][\"label\"].astype(int).to_numpy()\n",
    "    y_prob = np.zeros(len(idx), dtype=np.float32)\n",
    "\n",
    "    n = len(idx)\n",
    "    for i, ridx in enumerate(idx):\n",
    "        if (i + 1) % INFER_LOG_EVERY == 0 or (i + 1) == n:\n",
    "            logger.info(f\"  [infer] {i+1}/{n} samples\")\n",
    "\n",
    "        wav = str(dfm.iloc[ridx][\"wav_name\"])\n",
    "        mel_png  = MEL_DIR / f\"{wav}.png\"\n",
    "        stft_png = STFT_DIR / f\"{wav}.png\"\n",
    "        if (not mel_png.exists()) or (not stft_png.exists()):\n",
    "            y_prob[i] = np.nan\n",
    "            continue\n",
    "\n",
    "        x, _, _ = make_single_input(str(mel_png), str(stft_png))\n",
    "        p = model.predict(x, verbose=0).reshape(-1)[0]\n",
    "        y_prob[i] = float(p)\n",
    "\n",
    "    return y_true, y_prob\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6) 抽樣策略\n",
    "# =============================================================================\n",
    "def pick_cases_by_cm(idx_all, y_true, y_pred, case_type: str, k: int):\n",
    "    if case_type == \"TP\":\n",
    "        mask = (y_true == 1) & (y_pred == 1)\n",
    "    elif case_type == \"TN\":\n",
    "        mask = (y_true == 0) & (y_pred == 0)\n",
    "    elif case_type == \"FP\":\n",
    "        mask = (y_true == 0) & (y_pred == 1)\n",
    "    elif case_type == \"FN\":\n",
    "        mask = (y_true == 1) & (y_pred == 0)\n",
    "    else:\n",
    "        raise ValueError(case_type)\n",
    "\n",
    "    cand = idx_all[mask]\n",
    "    if len(cand) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    if len(cand) <= k:\n",
    "        return cand\n",
    "    sel = rng.choice(cand, size=k, replace=False)\n",
    "    return np.array(sel, dtype=int)\n",
    "\n",
    "def pick_cases_by_prob_fallback(idx_all, y_true, y_prob, case_type: str, k: int):\n",
    "    # 抽不到某類時的補齊策略：用機率排序抓極端案例\n",
    "    # 小發現：TN-like 與 FN-like 常常會變成很相似的一群，代表模型幾乎只靠一個訊號在決策\n",
    "    idx_all = np.asarray(idx_all).astype(int)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "\n",
    "    if case_type in (\"TN\", \"FP\"):\n",
    "        cand_mask = (y_true == 0)\n",
    "    else:\n",
    "        cand_mask = (y_true == 1)\n",
    "\n",
    "    cand_idx = idx_all[cand_mask]\n",
    "    cand_prob = y_prob[cand_mask]\n",
    "    if len(cand_idx) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    if case_type in (\"TN\", \"FN\"):\n",
    "        order = np.argsort(cand_prob)\n",
    "    else:\n",
    "        order = np.argsort(-cand_prob)\n",
    "\n",
    "    sel = cand_idx[order[:min(k, len(order))]]\n",
    "    return np.array(sel, dtype=int)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7) Main\n",
    "# =============================================================================\n",
    "def main():\n",
    "    dfm = load_manifest()\n",
    "    fold_to_test = rebuild_fold_test_indices(dfm)\n",
    "\n",
    "    cam_index_rows = []\n",
    "\n",
    "    for w_name in ALLOWED_WEIGHTS:\n",
    "        w_path = OUT_DIR / w_name\n",
    "        if not w_path.exists():\n",
    "            raise FileNotFoundError(f\"Allowed weight not found: {w_path}\")\n",
    "\n",
    "        m = re.match(r\"fold(\\d+)_best_by_valauroc_epoch(\\d+)\\.weights\\.h5$\", w_name)\n",
    "        if not m:\n",
    "            raise ValueError(f\"Bad allowed weight filename format: {w_name}\")\n",
    "\n",
    "        fold = int(m.group(1))\n",
    "        best_epoch_from_name = int(m.group(2))\n",
    "\n",
    "        best_csv = BEST_CSV_DIR / f\"fold{fold:02d}_best_metrics.csv\"\n",
    "        best_thr = DEFAULT_THR\n",
    "        if best_csv.exists():\n",
    "            d = pd.read_csv(best_csv).iloc[0].to_dict()\n",
    "            try:\n",
    "                best_thr = float(d.get(\"best_thr_on_val\", DEFAULT_THR))\n",
    "            except Exception:\n",
    "                best_thr = DEFAULT_THR\n",
    "\n",
    "        fold_out = EXPL_DIR / f\"fold{fold:02d}\"\n",
    "        fold_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        logger.info(\"------------------------------------------------------------\")\n",
    "        logger.info(f\"==== [Fold {fold:02d}] load weights (restricted): {w_path}\")\n",
    "        logger.info(f\"[Fold {fold:02d}] epoch(from filename)={best_epoch_from_name}\")\n",
    "        logger.info(f\"[Fold {fold:02d}] best_thr_on_val={best_thr:.3f}\")\n",
    "        logger.info(f\"[Fold {fold:02d}] output_dir={fold_out}\")\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = build_dual_shared_effnet_train_like(l2=1e-4, dropout=0.35, head_units=64)\n",
    "        set_backbone_trainable(model, trainable=True, unfreeze_ratio=0.2)\n",
    "        model.load_weights(str(w_path))\n",
    "\n",
    "        cam_model_mel, cam_model_stft = build_cam_models(model)\n",
    "\n",
    "        test_idx = fold_to_test.get(fold, None)\n",
    "        if test_idx is None:\n",
    "            logger.info(f\"[Fold {fold:02d}] test_idx not found, skip.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"[Fold {fold:02d}] infer test probs ... (n={len(test_idx)})\")\n",
    "        y_true, y_prob = infer_probs_for_indices(model, dfm, test_idx)\n",
    "\n",
    "        ok = np.isfinite(y_prob)\n",
    "        y_true_ok = y_true[ok]\n",
    "        y_prob_ok = y_prob[ok]\n",
    "        test_idx_ok = test_idx[ok]\n",
    "\n",
    "        y_pred_ok = (y_prob_ok >= best_thr).astype(int)\n",
    "        cm = confusion_matrix(y_true_ok, y_pred_ok, labels=[0, 1])\n",
    "        logger.info(f\"[Fold {fold:02d}] TEST cm=\\n{cm}\")\n",
    "\n",
    "        cases = {}\n",
    "        for ct in [\"TP\", \"TN\", \"FP\", \"FN\"]:\n",
    "            sel = pick_cases_by_cm(test_idx_ok, y_true_ok, y_pred_ok, ct, K_PER_CASE)\n",
    "            if len(sel) == 0 and FALLBACK_PROB_RANKING:\n",
    "                sel = pick_cases_by_prob_fallback(test_idx_ok, y_true_ok, y_prob_ok, ct, K_PER_CASE)\n",
    "                logger.info(f\"[Fold {fold:02d}] {ct} cm-picked=0 -> fallback prob-ranking picked={len(sel)}\")\n",
    "            else:\n",
    "                logger.info(f\"[Fold {fold:02d}] {ct} picked: {len(sel)}\")\n",
    "            cases[ct] = sel\n",
    "\n",
    "        for ct, sel_idx in cases.items():\n",
    "            if len(sel_idx) == 0:\n",
    "                continue\n",
    "            logger.info(f\"[Fold {fold:02d}] render {ct}: {len(sel_idx)} samples\")\n",
    "\n",
    "            for j, ridx in enumerate(sel_idx, start=1):\n",
    "                if j % RENDER_LOG_EVERY == 0 or j == len(sel_idx):\n",
    "                    logger.info(f\"  [{ct}] {j}/{len(sel_idx)}\")\n",
    "\n",
    "                row = dfm.iloc[int(ridx)]\n",
    "                wav = str(row[\"wav_name\"])\n",
    "                pid = int(row[\"patient_id\"])\n",
    "                y_t = int(row[\"label\"])\n",
    "\n",
    "                mel_png  = MEL_DIR / f\"{wav}.png\"\n",
    "                stft_png = STFT_DIR / f\"{wav}.png\"\n",
    "                if (not mel_png.exists()) or (not stft_png.exists()):\n",
    "                    continue\n",
    "\n",
    "                x, mel_img3, stft_img3 = make_single_input(str(mel_png), str(stft_png))\n",
    "\n",
    "                cam_mel,  prob_mel  = grad_cam(cam_model_mel,  x)\n",
    "                cam_stft, prob_stft = grad_cam(cam_model_stft, x)\n",
    "\n",
    "                prob = prob_mel\n",
    "                y_p = int(prob >= best_thr)\n",
    "\n",
    "                dcam = cam_mel - cam_stft\n",
    "                dcam = dcam - dcam.min()\n",
    "                dcam = dcam / (dcam.max() + 1e-9)\n",
    "\n",
    "                stem = (\n",
    "                    f\"fold{fold:02d}_{ct}_pid{pid}_\"\n",
    "                    f\"{wav.replace('.wav','')}_yt{y_t}_yp{y_p}_\"\n",
    "                    f\"p{prob:.3f}_thr{best_thr:.3f}\"\n",
    "                )\n",
    "\n",
    "                fig = overlay_cam_on_image(mel_img3, cam_mel, alpha=0.45)\n",
    "                out1 = fold_out / f\"{stem}__mel_cam.png\"\n",
    "                fig.savefig(out1, dpi=180, bbox_inches=\"tight\")\n",
    "                plt.close(fig)\n",
    "\n",
    "                fig = overlay_cam_on_image(stft_img3, cam_stft, alpha=0.45)\n",
    "                out2 = fold_out / f\"{stem}__stft_cam.png\"\n",
    "                fig.savefig(out2, dpi=180, bbox_inches=\"tight\")\n",
    "                plt.close(fig)\n",
    "\n",
    "                plt.figure(figsize=(4.2, 4.2))\n",
    "                plt.imshow(dcam)\n",
    "                plt.title(\"ΔCAM (mel - stft)\")\n",
    "                plt.axis(\"off\")\n",
    "                out3 = fold_out / f\"{stem}__dcam.png\"\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out3, dpi=180, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "\n",
    "                cam_index_rows.append({\n",
    "                    \"fold\": fold,\n",
    "                    \"case_type\": ct,\n",
    "                    \"patient_id\": pid,\n",
    "                    \"wav_name\": wav,\n",
    "                    \"y_true\": y_t,\n",
    "                    \"y_prob\": float(prob),\n",
    "                    \"y_pred\": int(y_p),\n",
    "                    \"thr\": float(best_thr),\n",
    "                    \"weights_used\": str(w_path),\n",
    "                    \"mel_cam_png\": str(out1),\n",
    "                    \"stft_cam_png\": str(out2),\n",
    "                    \"dcam_png\": str(out3),\n",
    "                })\n",
    "\n",
    "        logger.info(f\"[Fold {fold:02d}] done.\")\n",
    "\n",
    "    idx_csv = EXPL_DIR / \"cam_index.csv\"\n",
    "    pd.DataFrame(cam_index_rows).to_csv(idx_csv, index=False, encoding=\"utf-8\")\n",
    "    logger.info(\"------------------------------------------------------------\")\n",
    "    logger.info(f\"[Done] CAM index saved: {idx_csv}\")\n",
    "    logger.info(f\"[Done] CAM images saved under: {EXPL_DIR}/fold**/\")\n",
    "    logger.info(\"==== End explain_cam.py ====\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba05ea-3c25-4d9d-a1d4-3b593714e4ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# explain_cam.py（Grad-CAM + ΔCAM）流程圖\n",
    "# =============================================================================\n",
    "# 用 Graphviz 把 explain_cam.py 的處理步驟畫成流程圖，方便放報告或論文\n",
    "# 輸入：manifest、Mel/STFT 圖、指定的五個權重、每折最佳門檻 CSV\n",
    "# 輸出：流程圖 PNG，固定存到 data/out/explain/cam/\n",
    "# 小觀察：流程看起來很長，但真正吃時間的是 test 推論與逐張疊圖輸出\n",
    "# =============================================================================\n",
    "\n",
    "from graphviz import Digraph\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def draw_explain_cam_flow_cn():\n",
    "    # 輸出位置固定，避免到處散落\n",
    "    out_dir = Path(\"/home/jovyan/114-1_HA/data/out/explain/cam\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_png = out_dir / \"流程圖_explain_cam_GradCAM_ΔCAM.png\"\n",
    "\n",
    "    g = Digraph(\"流程圖_explain_cam\", format=\"png\")\n",
    "    g.attr(rankdir=\"LR\", splines=\"ortho\", nodesep=\"0.35\", ranksep=\"0.55\")\n",
    "    g.attr(\"node\", shape=\"box\", style=\"rounded\", fontsize=\"11\")\n",
    "\n",
    "    # ========== 輸入 ==========\n",
    "    with g.subgraph(name=\"cluster_in\") as c:\n",
    "        c.attr(label=\"輸入資料與依賴檔案\", style=\"rounded\")\n",
    "        c.node(\n",
    "            \"IN1\",\n",
    "            \"清單資料 manifest_S_only.csv\\n欄位 wav_name, patient_id, label\\n用途 連到圖檔與真實標籤\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"IN2\",\n",
    "            \"影像資料\\nMel PNG pic_v4/mel/*.png\\nSTFT PNG pic_v4/stft/*.png\\n用途 作為雙輸入推論與疊圖底圖\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"IN3\",\n",
    "            \"權重白名單 五個\\nfold**_best_by_valauroc_epochXXX.weights.h5\\n用途 限縮只看最關鍵的模型版本\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"IN4\",\n",
    "            \"每折最佳門檻 fold**_best_metrics.csv\\n欄位 best_thr_on_val\\n用途 推論後切 TP TN FP FN\\n備用 找不到就用 0.5\"\n",
    "        )\n",
    "\n",
    "    # ========== 每折處理 ==========\n",
    "    with g.subgraph(name=\"cluster_loop\") as c:\n",
    "        c.attr(label=\"每折處理流程 只跑白名單五個權重\", style=\"rounded\")\n",
    "\n",
    "        c.node(\"S1\", \"解析權重檔名\\n抽出 fold 與 epoch\\n順便檢查格式是否正確\")\n",
    "        c.node(\n",
    "            \"S2\",\n",
    "            \"重建切分 對齊訓練\\nStratifiedKFold 5 折 shuffle seed=42\\n本折 test set 使用 val_idx\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S3\",\n",
    "            \"建立模型 與訓練一致\\n雙輸入 shared EfficientNetB0\\nmel_gap stft_gap concat head prob\"\n",
    "        )\n",
    "        c.node(\"S4\", \"載入本折權重\\nKeras 3 直接 load_weights\\n避免 by_name\")\n",
    "        c.node(\n",
    "            \"S5\",\n",
    "            \"建立 CAM 子模型\\n輸出 feature_map 與 prob\\nmel_feat 取 mel_gap.input\\nstft_feat 取 stft_gap.input\\n小提醒 這樣才不會出現 grads=None\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S6\",\n",
    "            \"test 推論\\n逐筆讀 mel stft 圖\\n輸出 prob\\n不經意發現 這段最容易卡在缺圖或讀檔慢\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S7\",\n",
    "            \"門檻分類\\nthr 來自 best_thr_on_val\\n沒有就用 0.5\\n計算 TP TN FP FN 混淆矩陣\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S8\",\n",
    "            \"抽樣\\n每類抽 K_PER_CASE 張\\n抽不到就用機率排序補齊\\n用途 每折仍能產出完整案例組合\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S9\",\n",
    "            \"逐樣本產圖\\nGrad-CAM mel\\nGrad-CAM stft\\nΔCAM = mel - stft\\n正規化後輸出 overlay\"\n",
    "        )\n",
    "        c.node(\n",
    "            \"S10\",\n",
    "            \"記錄索引\\n存檔路徑 標籤 機率 門檻 權重\\n最後彙整成 cam_index.csv\"\n",
    "        )\n",
    "\n",
    "    # ========== 輸出 ==========\n",
    "    with g.subgraph(name=\"cluster_out\") as c:\n",
    "        c.attr(label=\"輸出產物\", style=\"rounded\")\n",
    "        c.node(\n",
    "            \"OUT1\",\n",
    "            \"本折 CAM 圖檔\\n__mel_cam.png\\n__stft_cam.png\\n__dcam.png\\n位置 explain/cam/fold**/\"\n",
    "        )\n",
    "        c.node(\"OUT2\", \"索引表 cam_index.csv\\n每張圖的 meta 與路徑\")\n",
    "        c.node(\"OUT3\", \"執行紀錄 log_explain/explain_cam_*.log\\n用途 回溯抽樣與缺圖狀況\")\n",
    "\n",
    "    # ========== 連線 ==========\n",
    "    g.edge(\"IN3\", \"S1\")\n",
    "    g.edge(\"IN1\", \"S2\")\n",
    "    g.edge(\"S1\", \"S3\")\n",
    "    g.edge(\"S3\", \"S4\")\n",
    "    g.edge(\"S4\", \"S5\")\n",
    "    g.edge(\"IN2\", \"S6\")\n",
    "    g.edge(\"S2\", \"S6\")\n",
    "    g.edge(\"S6\", \"S7\")\n",
    "    g.edge(\"IN4\", \"S7\")\n",
    "    g.edge(\"S7\", \"S8\")\n",
    "    g.edge(\"S8\", \"S9\")\n",
    "    g.edge(\"S9\", \"S10\")\n",
    "\n",
    "    g.edge(\"S9\", \"OUT1\")\n",
    "    g.edge(\"S10\", \"OUT2\")\n",
    "    g.edge(\"S1\", \"OUT3\")\n",
    "\n",
    "    g.render(filename=str(out_png).replace(\".png\", \"\"), cleanup=True)\n",
    "    print(f\"已輸出流程圖：{out_png}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    draw_explain_cam_flow_cn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2faa0-38b1-46c5-9bdd-b70a49aa4357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bf819-6a6c-442c-a0f2-3165da5e6c66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pip install graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "def draw_explain_feature_flow(out_png=\"flow_explain_feature.png\"):\n",
    "    g = Digraph(\"explain_feature_flow\", format=\"png\")\n",
    "    g.attr(rankdir=\"LR\", splines=\"ortho\", nodesep=\"0.35\", ranksep=\"0.5\")\n",
    "    g.attr(\"node\", shape=\"box\", style=\"rounded\", fontsize=\"11\")\n",
    "\n",
    "    with g.subgraph(name=\"cluster_inputs\") as c:\n",
    "        c.attr(label=\"Inputs / Artifacts\", style=\"rounded\")\n",
    "        c.node(\"M\", \"manifest_S_only.csv\\n(wav_name, patient_id, label)\")\n",
    "        c.node(\"I\", \"Mel PNGs + STFT PNGs\\n(pic_v4/mel, pic_v4/stft)\")\n",
    "        c.node(\"W\", \"Allowed weights ×5\\n(fold**_best_by_valauroc_epochXXX.weights.h5)\")\n",
    "\n",
    "    with g.subgraph(name=\"cluster_fold\") as c:\n",
    "        c.attr(label=\"Per-Fold Loop\", style=\"rounded\")\n",
    "        c.node(\"F0\", \"Rebuild fold test indices\\nStratifiedKFold(5, shuffle=True, seed=42)\")\n",
    "        c.node(\"F1\", \"Build model (same as training)\\nDual-input + shared EfficientNetB0\\nGAP → concat → head → prob\")\n",
    "        c.node(\"F2\", \"Load weights for fold\")\n",
    "        c.node(\"F3\", \"Sample N test examples\\nN_SAMPLES_PER_FOLD (random)\")\n",
    "        c.node(\"F4\", \"Load images + predict base prob\\np_i = model(mel_i, stft_i)\")\n",
    "        c.node(\"F5\", \"Compute mean images\\nmel_mean, stft_mean (baseline replacement)\")\n",
    "        c.node(\"F6\", \"Branch contribution\\nmel_off: replace mel_i → mel_mean\\nstft_off: replace stft_i → stft_mean\\nΔp = p_i - p_replaced\")\n",
    "        c.node(\"F7\", \"Occlusion importance: Frequency bands\\nSplit H into N_FREQ_BANDS\\nFor each band: occlude band → Δp mean\")\n",
    "        c.node(\"F8\", \"Occlusion importance: Time segments\\nSplit W into N_TIME_SEGS\\nFor each seg: occlude seg → Δp mean\")\n",
    "        c.node(\"F9\", \"Save CSVs per fold\\nfreq_importance.csv\\ntime_importance.csv\\nbranch_contrib.csv\")\n",
    "        c.node(\"F10\", \"Append fold summary\\nmel_branch_mean, stft_branch_mean\")\n",
    "\n",
    "    with g.subgraph(name=\"cluster_outputs\") as c:\n",
    "        c.attr(label=\"Outputs\", style=\"rounded\")\n",
    "        c.node(\"O1\", \"fold##_freq_importance.csv\\n(mel, stft)\")\n",
    "        c.node(\"O2\", \"fold##_time_importance.csv\\n(mel, stft)\")\n",
    "        c.node(\"O3\", \"fold##_branch_contrib.csv\\n(mel_off, stft_off)\")\n",
    "        c.node(\"O4\", \"feature_summary_allfolds.csv\\n(branch means across folds)\")\n",
    "\n",
    "    g.edge(\"M\", \"F0\")\n",
    "    g.edge(\"W\", \"F1\")\n",
    "    g.edge(\"F0\", \"F3\")\n",
    "    g.edge(\"F1\", \"F2\")\n",
    "    g.edge(\"F2\", \"F4\")\n",
    "    g.edge(\"I\", \"F4\")\n",
    "    g.edge(\"F4\", \"F5\")\n",
    "    g.edge(\"F5\", \"F6\")\n",
    "    g.edge(\"F4\", \"F7\")\n",
    "    g.edge(\"F4\", \"F8\")\n",
    "    g.edge(\"F6\", \"F9\")\n",
    "    g.edge(\"F7\", \"F9\")\n",
    "    g.edge(\"F8\", \"F9\")\n",
    "    g.edge(\"F9\", \"F10\")\n",
    "    g.edge(\"F9\", \"O1\")\n",
    "    g.edge(\"F9\", \"O2\")\n",
    "    g.edge(\"F9\", \"O3\")\n",
    "    g.edge(\"F10\", \"O4\")\n",
    "\n",
    "    g.render(filename=out_png.replace(\".png\", \"\"), cleanup=True)\n",
    "    print(f\"[Saved] {out_png}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    draw_explain_feature_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e39d35-6af6-45a5-b6d8-1b4dfef73381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出 fold01 下所有 CAM 圖檔\n",
    "# 目標：找出模型輸出機率最接近門檻值的樣本\n",
    "# 越接近門檻的樣本，通常越能反映模型猶豫區域\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# 使用當時驗證集選出的最佳門檻\n",
    "thr = 0.315\n",
    "\n",
    "# CAM 圖檔所在資料夾\n",
    "d = Path(\"/home/jovyan/114-1_HA/data/out/explain/cam/fold01\")\n",
    "\n",
    "# 從檔名中擷取機率 p 與門檻 thr\n",
    "# 檔名結尾只處理 mel_cam / stft_cam / dcam 三種\n",
    "pat = re.compile(\n",
    "    r\"_p(?P<p>\\d+\\.\\d+)_thr(?P<thr>\\d+\\.\\d+).*_(mel_cam|stft_cam|dcam)\\.png$\"\n",
    ")\n",
    "\n",
    "items = []\n",
    "\n",
    "# 掃描所有 png，僅保留符合命名規則者\n",
    "for f in d.glob(\"*.png\"):\n",
    "    m = pat.search(f.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    # 從檔名取出模型預測機率\n",
    "    p = float(m.group(\"p\"))\n",
    "\n",
    "    # 儲存與門檻的距離，方便排序\n",
    "    items.append((abs(p - thr), p, f.name))\n",
    "\n",
    "# 依 |p - thr| 由小到大排序\n",
    "# 排序前幾名通常是 decision boundary 附近的關鍵樣本\n",
    "items.sort()\n",
    "\n",
    "# 取最接近門檻的前 10 張\n",
    "items[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd26479-cf89-4a34-85df-32cf9a0dffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd754df0-a511-48e3-a364-73d68a1e0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path(\"/home/jovyan/114-1_HA/data/pic_v3/mel\")\n",
    "print(\"exists:\", (p/\"1_S1_1.png\").exists())\n",
    "print(\"similar:\", sorted([x.name for x in p.glob(\"1_S1_1.*\")])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf1a33-c64e-45d3-98ec-1b61261a961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight只用在 train loss\n",
    "Checkpoint：監控 val_auroc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
